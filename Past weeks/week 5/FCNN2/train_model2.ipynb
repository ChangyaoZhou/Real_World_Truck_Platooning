{"cells":[{"cell_type":"markdown","metadata":{"id":"a66201df"},"source":["### 1 Loading Dataset"],"id":"a66201df"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1966,"status":"ok","timestamp":1643023900770,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"_R6k7PwWZOQx","outputId":"ae536410-0002-443a-f916-36569fa5d753"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import sys\n","import os\n","\n","drive.mount('/content/drive')\n","sys.path.insert(0,'/content/drive/My Drive/Project/model1and2/')"],"id":"_R6k7PwWZOQx"},{"cell_type":"code","source":["!/opt/bin/nvidia-smi"],"metadata":{"id":"DvUpvjvtooKI","executionInfo":{"status":"ok","timestamp":1643023796875,"user_tz":-60,"elapsed":210,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}},"outputId":"6742f909-54a5-4892-8415-f7e96bf812bc","colab":{"base_uri":"https://localhost:8080/"}},"id":"DvUpvjvtooKI","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jan 24 11:29:56 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":33,"metadata":{"id":"7a91843a","executionInfo":{"status":"ok","timestamp":1643024090796,"user_tz":-60,"elapsed":247,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}}},"outputs":[],"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","\n","from my_datasets import MyDataset\n","from my_models import MyModel\n","from data.model_input_all import state_on, input_0, input_4, input_5, input_6\n","from data.model_gt_all import label_on,label_0, label_4, label_5, label_6"],"id":"7a91843a"},{"cell_type":"code","execution_count":34,"metadata":{"id":"97636c30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643024093117,"user_tz":-60,"elapsed":241,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}},"outputId":"0efb1b6e-e373-4658-e266-ca791e0515ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2"],"id":"97636c30"},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239,"status":"ok","timestamp":1643024096122,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"8ea6d0e6","outputId":"c6cf68f7-c7ca-4908-c0b3-9b1ffca7868e"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(torch.cuda.is_available())\n","print(device)"],"id":"8ea6d0e6"},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1643023917768,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"8c746828","outputId":"bf0d0b61-0ef8-420b-af56-244ea71f7642"},"outputs":[{"output_type":"stream","name":"stdout","text":["(30800, 8)\n","(30800, 2)\n","(30800, 7)\n","[ 6.65045929 -3.0562439  -0.04300366  4.93891158  4.68660979  0.68872645\n","  0.1014157 ]\n"]}],"source":["# gather all data\n","input_all = np.concatenate((state_on, input_0, input_4, input_5, input_6), axis = 0) \n","print(input_all.shape) \n","label_all = np.concatenate((label_on,label_0, label_4, label_5, label_6), axis = 0)\n","print(label_all.shape) \n","data_all = np.zeros((input_all.shape[0], 7)) \n","data_all[:,0] = input_all[:,4] - input_all[:,0]\n","data_all[:,1] = input_all[:,5] - input_all[:,1]\n","data_all[:,2] = input_all[:,6] - input_all[:,2]\n","data_all[:,3] = input_all[:,3]\n","data_all[:,4] = input_all[:,7]\n","data_all[:,5:] = label_all\n","np.random.shuffle(data_all)\n","print(data_all.shape)\n","print(data_all[0])"],"id":"8c746828"},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1643023919668,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"5b935cb0","outputId":"2b400773-a473-4152-c410-9dadd0a8b6b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["(30800, 5)\n","[21560.  6160.  3080.]\n","(30800, 2)\n","[21560.  6160.  3080.]\n","train input shape (21560, 5)\n"]}],"source":["def split_dataset(data, split_list):\n","    print(data.shape)\n","    split_num = data.shape[0] * np.array(split_list)\n","    print(split_num)\n","    return data[:round(split_num[0]), :], data[round(split_num[0]):round(split_num[1]+split_num[0]), :], data[round(split_num[1]+split_num[0]):, :]\n","\n","split_list = [0.7, 0.2, 0.1]\n","train_input, val_input, test_input = split_dataset(data_all[:, :5], split_list)\n","train_label, val_label, test_label = split_dataset(data_all[:, 5:], split_list) \n","print('train input shape', train_input.shape)"],"id":"5b935cb0"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239,"status":"ok","timestamp":1643023921521,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"e5f15563","outputId":"3407c6ed-e3bd-4158-9f51-615e75e62a1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train size: 21560\n","Validation size: 6160\n","Test size: 3080\n","Input size:  (5,)\n","Label size:  (2,)\n"]}],"source":["# test_dataset with only one sample for overfitting\n","over_input = data_all[:2, :5]\n","over_label = data_all[:2, 5:]\n","\n","train_data = MyDataset(states = train_input, labels = train_label)\n","val_data = MyDataset(states = val_input, labels = val_label)\n","test_data = MyDataset(states = test_input, labels = test_label)\n","over_data = MyDataset(states = over_input, labels = over_label)   \n","\n","train_loader = DataLoader(dataset=train_data, batch_size=256, shuffle=True)\n","val_loader = DataLoader(dataset=val_data, batch_size=256, shuffle=True)\n","test_loader = DataLoader(dataset=test_data, batch_size=128, shuffle=True)\n","over_loader = DataLoader(dataset=over_data, batch_size=2, shuffle=True)\n","\n","print(\"Train size: %i\" % len(train_data))\n","print(\"Validation size: %i\" % len(val_data))\n","print(\"Test size: %i\" % len(test_data))\n","print(\"Input size: \", train_data[0][0].shape)\n","print(\"Label size: \", train_data[0][1].shape)"],"id":"e5f15563"},{"cell_type":"markdown","metadata":{"id":"8b4f5b2d"},"source":["### 2 Defining Neural Network"],"id":"8b4f5b2d"},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1643024102229,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"20a8445a","outputId":"68b078b6-0576-42b1-a8d8-6fdcaef42b7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["MyModel(\n","  (predictor): Sequential(\n","    (0): Linear(in_features=8, out_features=256, bias=True)\n","    (1): ReLU()\n","    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Linear(in_features=256, out_features=512, bias=True)\n","    (4): ReLU()\n","    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): Linear(in_features=512, out_features=1024, bias=True)\n","    (7): ReLU()\n","    (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): Linear(in_features=1024, out_features=512, bias=True)\n","    (10): ReLU()\n","    (11): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): Linear(in_features=512, out_features=256, bias=True)\n","    (13): ReLU()\n","    (14): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (15): Linear(in_features=256, out_features=2, bias=True)\n","  )\n",")\n"]}],"source":["mynet = MyModel(neurons = [256, 512, 1024, 512, 256]) \n","print(mynet)"],"id":"20a8445a"},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1643024111444,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"484ee84f","outputId":"c38db337-fc16-4e0c-fc9c-c5a49be8ff76"},"outputs":[{"output_type":"stream","name":"stdout","text":["1,320,962 total parameters.\n","1,320,962 trainable parameters.\n"]}],"source":["total_params = sum(p.numel() for p in mynet.parameters())\n","print(f'{total_params:,} total parameters.')\n","total_trainable_params = sum(\n","    p.numel() for p in mynet.parameters() if p.requires_grad)\n","print(f'{total_trainable_params:,} trainable parameters.')"],"id":"484ee84f"},{"cell_type":"markdown","metadata":{"id":"78ba5bf4"},"source":["### 3 Training Neural network"],"id":"78ba5bf4"},{"cell_type":"code","execution_count":30,"metadata":{"id":"f2e32edb","executionInfo":{"status":"ok","timestamp":1643024039052,"user_tz":-60,"elapsed":228,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}}},"outputs":[],"source":["mycriterion = nn.MSELoss() \n","myoptimizer = optim.Adam(mynet.parameters(), lr=1e-4, eps = 1e-08) "],"id":"f2e32edb"},{"cell_type":"code","execution_count":31,"metadata":{"id":"3fae618d","scrolled":true,"executionInfo":{"status":"ok","timestamp":1643024040593,"user_tz":-60,"elapsed":319,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}}},"outputs":[],"source":["def run_epoch(model,criterion,optimizer,dataloader,iftrain):    \n","    running_loss = 0.0  \n","    \n","    #Iterating through the minibatches of the data\n","    for i, data in enumerate(dataloader, 0): \n","        X, y = data\n","        X = X.cuda()\n","        y = y.cuda()\n","        #print(i)\n","        if iftrain:  \n","            #model.train()\n","            optimizer.zero_grad()\n","            y_pred = model(X.to(torch.float32))\n","            #y_pred[:,1] = y_pred[:,1] * 20\n","            #y[:,1] = y[:,1] * 20\n","            y_pred = y_pred.float()\n","            y = y.float() \n","            \n","            loss = criterion(y_pred, y)  \n","            loss.backward()             \n","            optimizer.step()            \n","            running_loss += loss.item() \n","        else:\n","            #model.eval()\n","            y_pred = model(X.to(torch.float32))\n","            y_pred = y_pred.float()  \n","            y = y.float()\n","            #y_pred[:,1] = y_pred[:,1] * 20\n","            #y[:,1] = y[:,1] * 20 \n","            loss = criterion(y_pred , y)  \n","            running_loss += loss.item()    \n","    return running_loss    "],"id":"3fae618d"},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":667,"status":"error","timestamp":1643024043602,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"bf32e03a","outputId":"5fc3fb47-c920-436a-b703-1c40b2bf3beb"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-4f6850367083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     train_loss = run_epoch(model=mynet,criterion=mycriterion,\n\u001b[1;32m      8\u001b[0m                            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyoptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mover_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                            iftrain=True)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     val_loss =  run_epoch(model=mynet,criterion=mycriterion,\n","\u001b[0;32m<ipython-input-31-0b9e58a44b92>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, criterion, optimizer, dataloader, iftrain)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m#model.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m#y_pred[:,1] = y_pred[:,1] * 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#y[:,1] = y[:,1] * 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Project/model1and2/my_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x5 and 8x256)"]}],"source":["# test if the model will overfit with only one sample\n","max_epochs = 1000 \n","train_history = []\n","val_history = []\n","\n","for epoch in range(max_epochs): \n","    train_loss = run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=over_loader,\n","                           iftrain=True)\n","    train_history.append(train_loss)\n","    val_loss =  run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=over_loader,\n","                           iftrain=False)\n","    val_history.append(val_loss)\n","    if epoch % 50 == 49:\n","        print(f\"Epoch {epoch + 1: >3}/{max_epochs}, train_loss: %2e, val_loss: %2e \"% \n","          (train_loss/5, val_loss/5))"],"id":"bf32e03a"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1642763360715,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"6883ebae","outputId":"cb542059-d574-4caf-fd04-4ebb3009f6ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[12.4576, -9.5441,  0.0244, 11.3337,  8.4616],\n","        [ 8.3376, -6.6653, -0.0260,  4.9277,  5.8813]], dtype=torch.float64), tensor([[10.0000,  0.0122],\n","        [10.0000,  2.8510]], dtype=torch.float64)]\n","test 0\n","prediction: tensor([[1.0000, 0.0012],\n","        [1.0000, 0.2851]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([[1.0000, 0.0012],\n","        [1.0000, 0.2851]], device='cuda:0', dtype=torch.float64)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]}],"source":["# test inference \n","for i, data in enumerate(over_loader, 0): \n","        print(data)\n","        X = torch.tensor(data[0]).cuda()\n","        y = torch.tensor(data[1]).cuda()\n","        y_pred = mynet(X.to(torch.float32))\n","        if i < 10:\n","            print('test',i)\n","            print('prediction: {},\\nground truth：{}'.format(y_pred/10, y/10)) "],"id":"6883ebae"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1642763365330,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"93bdaf01","outputId":"7966964c-e508-44df-f886-c71e4174c067"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# plot the train&validation loss curve with only one sample\n","epochs = range(len(train_history))\n","plt.figure()\n","plt.plot(epochs, train_history, 'bo', label='Training loss')\n","plt.plot(epochs, val_history, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","\n","plt.legend()\n","plt.show()"],"id":"93bdaf01"},{"cell_type":"code","execution_count":null,"metadata":{"id":"03978b27"},"outputs":[],"source":["mycriterion = nn.MSELoss() \n","myoptimizer = optim.Adam(mynet.parameters(), lr=2e-6, eps = 1e-08) "],"id":"03978b27"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b784ca9a","scrolled":true,"executionInfo":{"status":"ok","timestamp":1642788634709,"user_tz":-60,"elapsed":441881,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}},"outputId":"07800f07-bf2c-446e-bd21-1396ce7db975"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_data 21560\n","Start training!\n","Epoch   2/1000, train_loss: 8.451576e-04, val_loss: 3.163411e+00 \n","Epoch   4/1000, train_loss: 8.361415e-04, val_loss: 3.354223e+00 \n","Epoch   6/1000, train_loss: 8.417031e-04, val_loss: 3.286757e+00 \n","Epoch   8/1000, train_loss: 8.697682e-04, val_loss: 3.157284e+00 \n","Epoch  10/1000, train_loss: 8.481015e-04, val_loss: 3.237529e+00 \n","Epoch  12/1000, train_loss: 8.443023e-04, val_loss: 3.179889e+00 \n","Epoch  14/1000, train_loss: 8.618788e-04, val_loss: 3.249718e+00 \n","Epoch  16/1000, train_loss: 8.550018e-04, val_loss: 3.171545e+00 \n","Epoch  18/1000, train_loss: 8.323403e-04, val_loss: 3.198881e+00 \n","Epoch  20/1000, train_loss: 8.236991e-04, val_loss: 3.205657e+00 \n","Epoch  22/1000, train_loss: 8.720227e-04, val_loss: 3.463562e+00 \n","Epoch  24/1000, train_loss: 8.778780e-04, val_loss: 3.218102e+00 \n","Epoch  26/1000, train_loss: 8.379135e-04, val_loss: 3.175299e+00 \n","Epoch  28/1000, train_loss: 8.375261e-04, val_loss: 3.163019e+00 \n","Epoch  30/1000, train_loss: 8.515796e-04, val_loss: 3.150533e+00 \n","Epoch  32/1000, train_loss: 8.806375e-04, val_loss: 3.178861e+00 \n","Epoch  34/1000, train_loss: 9.626685e-04, val_loss: 3.218896e+00 \n","Epoch  36/1000, train_loss: 8.533122e-04, val_loss: 3.212665e+00 \n","Epoch  38/1000, train_loss: 8.500737e-04, val_loss: 3.238820e+00 \n","Epoch  40/1000, train_loss: 8.452786e-04, val_loss: 3.167408e+00 \n","Epoch  42/1000, train_loss: 8.478314e-04, val_loss: 3.152495e+00 \n","Epoch  44/1000, train_loss: 8.874189e-04, val_loss: 3.265079e+00 \n","Epoch  46/1000, train_loss: 8.305586e-04, val_loss: 3.162573e+00 \n","Epoch  48/1000, train_loss: 8.447779e-04, val_loss: 3.170613e+00 \n","Epoch  50/1000, train_loss: 8.379202e-04, val_loss: 3.266952e+00 \n","Epoch  52/1000, train_loss: 8.716046e-04, val_loss: 3.197895e+00 \n","Epoch  54/1000, train_loss: 8.387077e-04, val_loss: 3.185936e+00 \n","Epoch  56/1000, train_loss: 8.277328e-04, val_loss: 3.150605e+00 \n","Epoch  58/1000, train_loss: 8.677839e-04, val_loss: 3.458904e+00 \n","Epoch  60/1000, train_loss: 8.396351e-04, val_loss: 3.180994e+00 \n","Epoch  62/1000, train_loss: 8.541874e-04, val_loss: 3.188903e+00 \n","Epoch  64/1000, train_loss: 8.471411e-04, val_loss: 3.193569e+00 \n","Epoch  66/1000, train_loss: 8.443282e-04, val_loss: 3.150265e+00 \n","Epoch  68/1000, train_loss: 8.419989e-04, val_loss: 3.269717e+00 \n","Epoch  70/1000, train_loss: 8.394622e-04, val_loss: 3.175740e+00 \n","Epoch  72/1000, train_loss: 8.477059e-04, val_loss: 3.408363e+00 \n","Epoch  74/1000, train_loss: 8.550951e-04, val_loss: 3.258448e+00 \n","Epoch  76/1000, train_loss: 8.562898e-04, val_loss: 3.234494e+00 \n","Epoch  78/1000, train_loss: 8.432108e-04, val_loss: 3.377922e+00 \n","Epoch  80/1000, train_loss: 8.497069e-04, val_loss: 3.185755e+00 \n","Epoch  82/1000, train_loss: 8.313369e-04, val_loss: 3.149215e+00 \n","Epoch  84/1000, train_loss: 8.325873e-04, val_loss: 3.416325e+00 \n","Epoch  86/1000, train_loss: 8.352352e-04, val_loss: 3.273100e+00 \n","Epoch  88/1000, train_loss: 8.519968e-04, val_loss: 3.156997e+00 \n","Epoch  90/1000, train_loss: 8.552007e-04, val_loss: 3.181286e+00 \n","Epoch  92/1000, train_loss: 8.389465e-04, val_loss: 3.228934e+00 \n","Epoch  94/1000, train_loss: 8.633639e-04, val_loss: 3.258495e+00 \n","Epoch  96/1000, train_loss: 8.336870e-04, val_loss: 3.364755e+00 \n","Epoch  98/1000, train_loss: 8.336054e-04, val_loss: 3.400808e+00 \n","Epoch 100/1000, train_loss: 8.394779e-04, val_loss: 3.194234e+00 \n","Epoch 102/1000, train_loss: 8.603503e-04, val_loss: 3.169058e+00 \n","Epoch 104/1000, train_loss: 8.381328e-04, val_loss: 3.378595e+00 \n","Epoch 106/1000, train_loss: 8.372378e-04, val_loss: 3.222492e+00 \n","Epoch 108/1000, train_loss: 8.755125e-04, val_loss: 3.348720e+00 \n","Epoch 110/1000, train_loss: 8.323986e-04, val_loss: 3.172517e+00 \n","Epoch 112/1000, train_loss: 8.285920e-04, val_loss: 3.531518e+00 \n","Epoch 114/1000, train_loss: 8.339929e-04, val_loss: 3.207213e+00 \n","Epoch 116/1000, train_loss: 8.314191e-04, val_loss: 3.172312e+00 \n","Epoch 118/1000, train_loss: 8.309135e-04, val_loss: 3.207569e+00 \n","Epoch 120/1000, train_loss: 8.426949e-04, val_loss: 3.187880e+00 \n","Epoch 122/1000, train_loss: 8.263161e-04, val_loss: 3.276881e+00 \n","Epoch 124/1000, train_loss: 8.267502e-04, val_loss: 3.291842e+00 \n","Epoch 126/1000, train_loss: 8.224060e-04, val_loss: 3.228609e+00 \n","Epoch 128/1000, train_loss: 8.425671e-04, val_loss: 3.505167e+00 \n","Epoch 130/1000, train_loss: 8.436723e-04, val_loss: 3.244949e+00 \n","Epoch 132/1000, train_loss: 8.297306e-04, val_loss: 3.175880e+00 \n","Epoch 134/1000, train_loss: 8.487425e-04, val_loss: 3.499245e+00 \n","Epoch 136/1000, train_loss: 8.742098e-04, val_loss: 3.272877e+00 \n","Epoch 138/1000, train_loss: 8.313025e-04, val_loss: 3.212742e+00 \n","Epoch 140/1000, train_loss: 8.473362e-04, val_loss: 3.244711e+00 \n","Epoch 142/1000, train_loss: 8.217152e-04, val_loss: 3.302220e+00 \n","Epoch 144/1000, train_loss: 8.213754e-04, val_loss: 3.157108e+00 \n","Epoch 146/1000, train_loss: 8.464270e-04, val_loss: 3.565399e+00 \n","Epoch 148/1000, train_loss: 8.224887e-04, val_loss: 3.182054e+00 \n","Epoch 150/1000, train_loss: 8.346286e-04, val_loss: 3.206256e+00 \n","Epoch 152/1000, train_loss: 8.359551e-04, val_loss: 3.437448e+00 \n","Epoch 154/1000, train_loss: 8.614510e-04, val_loss: 3.715931e+00 \n","Epoch 156/1000, train_loss: 8.103403e-04, val_loss: 3.311191e+00 \n","Epoch 158/1000, train_loss: 8.209385e-04, val_loss: 3.154917e+00 \n","Epoch 160/1000, train_loss: 8.425427e-04, val_loss: 3.214189e+00 \n","Epoch 162/1000, train_loss: 8.429037e-04, val_loss: 3.286700e+00 \n","Epoch 164/1000, train_loss: 8.847487e-04, val_loss: 3.212178e+00 \n","Epoch 166/1000, train_loss: 9.277390e-04, val_loss: 3.158763e+00 \n","Epoch 168/1000, train_loss: 8.253280e-04, val_loss: 3.509910e+00 \n","Epoch 170/1000, train_loss: 8.202726e-04, val_loss: 3.262638e+00 \n","Epoch 172/1000, train_loss: 8.174963e-04, val_loss: 3.582080e+00 \n","Epoch 174/1000, train_loss: 8.327559e-04, val_loss: 3.244819e+00 \n","Epoch 176/1000, train_loss: 8.871024e-04, val_loss: 3.283820e+00 \n","Epoch 178/1000, train_loss: 8.305772e-04, val_loss: 3.647352e+00 \n","Epoch 180/1000, train_loss: 8.182537e-04, val_loss: 3.392905e+00 \n","Epoch 182/1000, train_loss: 8.351060e-04, val_loss: 3.377624e+00 \n","Epoch 184/1000, train_loss: 8.138387e-04, val_loss: 3.330711e+00 \n","Epoch 186/1000, train_loss: 8.238443e-04, val_loss: 3.159783e+00 \n","Epoch 188/1000, train_loss: 8.520499e-04, val_loss: 3.287392e+00 \n","Epoch 190/1000, train_loss: 8.297684e-04, val_loss: 3.232525e+00 \n","Epoch 192/1000, train_loss: 8.617211e-04, val_loss: 3.293772e+00 \n","Epoch 194/1000, train_loss: 8.805517e-04, val_loss: 3.452382e+00 \n","Epoch 196/1000, train_loss: 8.259886e-04, val_loss: 3.282105e+00 \n","Epoch 198/1000, train_loss: 8.235223e-04, val_loss: 3.366828e+00 \n","Epoch 200/1000, train_loss: 8.477221e-04, val_loss: 3.153124e+00 \n","Epoch 202/1000, train_loss: 8.145956e-04, val_loss: 4.334040e+00 \n","Epoch 204/1000, train_loss: 8.140386e-04, val_loss: 3.201380e+00 \n","Epoch 206/1000, train_loss: 8.342099e-04, val_loss: 3.165299e+00 \n","Epoch 208/1000, train_loss: 8.291345e-04, val_loss: 3.333381e+00 \n","Epoch 210/1000, train_loss: 8.133178e-04, val_loss: 3.380502e+00 \n","Epoch 212/1000, train_loss: 8.534838e-04, val_loss: 3.201267e+00 \n","Epoch 214/1000, train_loss: 8.472799e-04, val_loss: 3.415471e+00 \n","Epoch 216/1000, train_loss: 8.075426e-04, val_loss: 3.396037e+00 \n","Epoch 218/1000, train_loss: 8.318106e-04, val_loss: 3.298113e+00 \n","Epoch 220/1000, train_loss: 8.281681e-04, val_loss: 3.241750e+00 \n","Epoch 222/1000, train_loss: 8.174435e-04, val_loss: 3.323648e+00 \n","Epoch 224/1000, train_loss: 8.439182e-04, val_loss: 3.155368e+00 \n","Epoch 226/1000, train_loss: 8.196259e-04, val_loss: 3.655410e+00 \n","Epoch 228/1000, train_loss: 8.238726e-04, val_loss: 3.190593e+00 \n","Epoch 230/1000, train_loss: 8.564893e-04, val_loss: 3.222421e+00 \n","Epoch 232/1000, train_loss: 8.255554e-04, val_loss: 3.366956e+00 \n","Epoch 234/1000, train_loss: 8.182610e-04, val_loss: 3.215639e+00 \n","Epoch 236/1000, train_loss: 8.220055e-04, val_loss: 3.194125e+00 \n","Epoch 238/1000, train_loss: 8.240883e-04, val_loss: 3.323773e+00 \n","Epoch 240/1000, train_loss: 8.211970e-04, val_loss: 3.348912e+00 \n","Epoch 242/1000, train_loss: 8.488598e-04, val_loss: 3.174298e+00 \n","Epoch 244/1000, train_loss: 8.184434e-04, val_loss: 3.180634e+00 \n","Epoch 246/1000, train_loss: 8.292952e-04, val_loss: 3.181012e+00 \n","Epoch 248/1000, train_loss: 8.138414e-04, val_loss: 3.164109e+00 \n","Epoch 250/1000, train_loss: 8.526406e-04, val_loss: 3.276690e+00 \n","Epoch 252/1000, train_loss: 8.208738e-04, val_loss: 3.198850e+00 \n","Epoch 254/1000, train_loss: 8.166390e-04, val_loss: 3.338226e+00 \n","Epoch 256/1000, train_loss: 8.107321e-04, val_loss: 3.331927e+00 \n","Epoch 258/1000, train_loss: 8.246694e-04, val_loss: 3.170268e+00 \n","Epoch 260/1000, train_loss: 8.087547e-04, val_loss: 3.208119e+00 \n","Epoch 262/1000, train_loss: 8.455854e-04, val_loss: 3.207756e+00 \n","Epoch 264/1000, train_loss: 8.191982e-04, val_loss: 3.570263e+00 \n","Epoch 266/1000, train_loss: 8.557936e-04, val_loss: 3.244160e+00 \n","Epoch 268/1000, train_loss: 8.222617e-04, val_loss: 3.159540e+00 \n","Epoch 270/1000, train_loss: 8.130743e-04, val_loss: 3.197119e+00 \n","Epoch 272/1000, train_loss: 8.125248e-04, val_loss: 3.328330e+00 \n","Epoch 274/1000, train_loss: 8.261314e-04, val_loss: 3.361816e+00 \n","Epoch 276/1000, train_loss: 8.106402e-04, val_loss: 3.775773e+00 \n","Epoch 278/1000, train_loss: 8.239840e-04, val_loss: 3.167114e+00 \n","Epoch 280/1000, train_loss: 8.129213e-04, val_loss: 3.263629e+00 \n","Epoch 282/1000, train_loss: 8.097593e-04, val_loss: 3.194614e+00 \n","Epoch 284/1000, train_loss: 8.419828e-04, val_loss: 3.160302e+00 \n","Epoch 286/1000, train_loss: 8.222846e-04, val_loss: 3.416775e+00 \n","Epoch 288/1000, train_loss: 8.258495e-04, val_loss: 3.156351e+00 \n","Epoch 290/1000, train_loss: 8.223829e-04, val_loss: 3.157926e+00 \n","Epoch 292/1000, train_loss: 8.222394e-04, val_loss: 3.186805e+00 \n","Epoch 294/1000, train_loss: 8.125286e-04, val_loss: 3.310697e+00 \n","Epoch 296/1000, train_loss: 8.054915e-04, val_loss: 3.416686e+00 \n","Epoch 298/1000, train_loss: 8.201538e-04, val_loss: 3.179106e+00 \n","Epoch 300/1000, train_loss: 8.247170e-04, val_loss: 3.163310e+00 \n","Epoch 302/1000, train_loss: 8.843339e-04, val_loss: 3.177353e+00 \n","Epoch 304/1000, train_loss: 8.090736e-04, val_loss: 3.178914e+00 \n","Epoch 306/1000, train_loss: 8.043373e-04, val_loss: 3.348386e+00 \n","Epoch 308/1000, train_loss: 8.048070e-04, val_loss: 3.188684e+00 \n","Epoch 310/1000, train_loss: 8.148718e-04, val_loss: 3.175755e+00 \n","Epoch 312/1000, train_loss: 8.261295e-04, val_loss: 3.159679e+00 \n","Epoch 314/1000, train_loss: 8.110112e-04, val_loss: 3.160319e+00 \n","Epoch 316/1000, train_loss: 8.378568e-04, val_loss: 3.240118e+00 \n","Epoch 318/1000, train_loss: 8.040818e-04, val_loss: 3.177758e+00 \n","Epoch 320/1000, train_loss: 8.830004e-04, val_loss: 3.184537e+00 \n","Epoch 322/1000, train_loss: 8.037939e-04, val_loss: 3.186341e+00 \n","Epoch 324/1000, train_loss: 8.207547e-04, val_loss: 3.242380e+00 \n","Epoch 326/1000, train_loss: 7.998601e-04, val_loss: 3.245880e+00 \n","Epoch 328/1000, train_loss: 7.973122e-04, val_loss: 3.237900e+00 \n","Epoch 330/1000, train_loss: 8.062143e-04, val_loss: 3.411953e+00 \n","Epoch 332/1000, train_loss: 8.164234e-04, val_loss: 3.167556e+00 \n","Epoch 334/1000, train_loss: 8.001497e-04, val_loss: 3.256342e+00 \n","Epoch 336/1000, train_loss: 8.105576e-04, val_loss: 3.315338e+00 \n","Epoch 338/1000, train_loss: 8.011159e-04, val_loss: 3.224418e+00 \n","Epoch 340/1000, train_loss: 8.097848e-04, val_loss: 3.193188e+00 \n","Epoch 342/1000, train_loss: 8.020379e-04, val_loss: 3.734027e+00 \n","Epoch 344/1000, train_loss: 8.191726e-04, val_loss: 3.266340e+00 \n","Epoch 346/1000, train_loss: 8.117307e-04, val_loss: 3.192230e+00 \n","Epoch 348/1000, train_loss: 8.060793e-04, val_loss: 3.174642e+00 \n","Epoch 350/1000, train_loss: 8.199293e-04, val_loss: 3.204484e+00 \n","Epoch 352/1000, train_loss: 8.127755e-04, val_loss: 3.303092e+00 \n","Epoch 354/1000, train_loss: 8.163759e-04, val_loss: 3.153794e+00 \n","Epoch 356/1000, train_loss: 8.120981e-04, val_loss: 3.240568e+00 \n","Epoch 358/1000, train_loss: 8.006876e-04, val_loss: 3.186702e+00 \n","Epoch 360/1000, train_loss: 8.111118e-04, val_loss: 3.192421e+00 \n","Epoch 362/1000, train_loss: 8.049777e-04, val_loss: 3.259984e+00 \n","Epoch 364/1000, train_loss: 8.370290e-04, val_loss: 3.237763e+00 \n","Epoch 366/1000, train_loss: 8.063184e-04, val_loss: 3.273831e+00 \n","Epoch 368/1000, train_loss: 9.736818e-04, val_loss: 3.227367e+00 \n","Epoch 370/1000, train_loss: 8.091874e-04, val_loss: 3.334697e+00 \n","Epoch 372/1000, train_loss: 8.055216e-04, val_loss: 3.204403e+00 \n","Epoch 374/1000, train_loss: 7.916272e-04, val_loss: 3.223307e+00 \n","Epoch 376/1000, train_loss: 8.634125e-04, val_loss: 3.257378e+00 \n","Epoch 378/1000, train_loss: 7.956526e-04, val_loss: 3.591799e+00 \n","Epoch 380/1000, train_loss: 7.901876e-04, val_loss: 3.258580e+00 \n","Epoch 382/1000, train_loss: 7.956143e-04, val_loss: 3.280404e+00 \n","Epoch 384/1000, train_loss: 8.008227e-04, val_loss: 3.165101e+00 \n","Epoch 386/1000, train_loss: 8.287182e-04, val_loss: 3.156442e+00 \n","Epoch 388/1000, train_loss: 8.042571e-04, val_loss: 3.289633e+00 \n","Epoch 390/1000, train_loss: 8.161689e-04, val_loss: 3.201033e+00 \n","Epoch 392/1000, train_loss: 8.028699e-04, val_loss: 3.157875e+00 \n","Epoch 394/1000, train_loss: 7.964752e-04, val_loss: 3.345474e+00 \n","Epoch 396/1000, train_loss: 7.933000e-04, val_loss: 3.154894e+00 \n","Epoch 398/1000, train_loss: 8.273017e-04, val_loss: 3.249524e+00 \n","Epoch 400/1000, train_loss: 8.037139e-04, val_loss: 3.489404e+00 \n","Epoch 402/1000, train_loss: 7.962453e-04, val_loss: 3.164731e+00 \n","Epoch 404/1000, train_loss: 7.969424e-04, val_loss: 3.161501e+00 \n","Epoch 406/1000, train_loss: 8.041075e-04, val_loss: 3.400747e+00 \n","Epoch 408/1000, train_loss: 7.964259e-04, val_loss: 3.161542e+00 \n","Epoch 410/1000, train_loss: 8.028272e-04, val_loss: 3.151244e+00 \n","Epoch 412/1000, train_loss: 8.066924e-04, val_loss: 3.275775e+00 \n","Epoch 414/1000, train_loss: 8.233671e-04, val_loss: 3.204884e+00 \n","Epoch 416/1000, train_loss: 8.137639e-04, val_loss: 3.219723e+00 \n","Epoch 418/1000, train_loss: 7.893065e-04, val_loss: 3.214620e+00 \n","Epoch 420/1000, train_loss: 8.018774e-04, val_loss: 3.198113e+00 \n","Epoch 422/1000, train_loss: 8.225180e-04, val_loss: 3.255288e+00 \n","Epoch 424/1000, train_loss: 7.949054e-04, val_loss: 3.422929e+00 \n","Epoch 426/1000, train_loss: 8.005508e-04, val_loss: 3.174212e+00 \n","Epoch 428/1000, train_loss: 7.932425e-04, val_loss: 3.160026e+00 \n","Epoch 430/1000, train_loss: 8.078984e-04, val_loss: 3.591887e+00 \n","Epoch 432/1000, train_loss: 7.933346e-04, val_loss: 3.328607e+00 \n","Epoch 434/1000, train_loss: 7.810620e-04, val_loss: 3.152635e+00 \n","Epoch 436/1000, train_loss: 8.006104e-04, val_loss: 3.283424e+00 \n","Epoch 438/1000, train_loss: 7.948133e-04, val_loss: 3.299744e+00 \n","Epoch 440/1000, train_loss: 7.898817e-04, val_loss: 3.203941e+00 \n","Epoch 442/1000, train_loss: 7.986250e-04, val_loss: 3.183217e+00 \n","Epoch 444/1000, train_loss: 7.963086e-04, val_loss: 3.156322e+00 \n","Epoch 446/1000, train_loss: 7.866245e-04, val_loss: 3.152633e+00 \n","Epoch 448/1000, train_loss: 8.533151e-04, val_loss: 3.342371e+00 \n","Epoch 450/1000, train_loss: 7.869112e-04, val_loss: 3.237842e+00 \n","Epoch 452/1000, train_loss: 8.034585e-04, val_loss: 3.236164e+00 \n","Epoch 454/1000, train_loss: 7.824287e-04, val_loss: 3.172940e+00 \n","Epoch 456/1000, train_loss: 7.818514e-04, val_loss: 3.246624e+00 \n","Epoch 458/1000, train_loss: 7.863159e-04, val_loss: 3.162597e+00 \n","Epoch 460/1000, train_loss: 7.886223e-04, val_loss: 3.173127e+00 \n","Epoch 462/1000, train_loss: 7.960997e-04, val_loss: 3.285340e+00 \n","Epoch 464/1000, train_loss: 7.955624e-04, val_loss: 3.158934e+00 \n","Epoch 466/1000, train_loss: 7.814536e-04, val_loss: 3.253655e+00 \n","Epoch 468/1000, train_loss: 7.978475e-04, val_loss: 3.229731e+00 \n","Epoch 470/1000, train_loss: 7.891724e-04, val_loss: 3.176688e+00 \n","Epoch 472/1000, train_loss: 7.858523e-04, val_loss: 3.162007e+00 \n","Epoch 474/1000, train_loss: 7.965066e-04, val_loss: 3.258198e+00 \n","Epoch 476/1000, train_loss: 9.845003e-04, val_loss: 3.337387e+00 \n","Epoch 478/1000, train_loss: 8.365166e-04, val_loss: 3.222337e+00 \n","Epoch 480/1000, train_loss: 7.797210e-04, val_loss: 3.197110e+00 \n","Epoch 482/1000, train_loss: 7.978681e-04, val_loss: 3.166049e+00 \n","Epoch 484/1000, train_loss: 8.575475e-04, val_loss: 3.176552e+00 \n","Epoch 486/1000, train_loss: 7.816433e-04, val_loss: 3.605983e+00 \n","Epoch 488/1000, train_loss: 8.223443e-04, val_loss: 3.219666e+00 \n","Epoch 490/1000, train_loss: 7.886912e-04, val_loss: 3.307816e+00 \n","Epoch 492/1000, train_loss: 7.752116e-04, val_loss: 3.233513e+00 \n","Epoch 494/1000, train_loss: 7.952079e-04, val_loss: 3.191116e+00 \n","Epoch 496/1000, train_loss: 7.995013e-04, val_loss: 3.210692e+00 \n","Epoch 498/1000, train_loss: 7.751576e-04, val_loss: 3.260565e+00 \n","Epoch 500/1000, train_loss: 7.848553e-04, val_loss: 3.160907e+00 \n","Epoch 502/1000, train_loss: 8.038179e-04, val_loss: 3.180157e+00 \n","Epoch 504/1000, train_loss: 7.879266e-04, val_loss: 3.169207e+00 \n","Epoch 506/1000, train_loss: 7.839352e-04, val_loss: 3.196752e+00 \n","Epoch 508/1000, train_loss: 7.905630e-04, val_loss: 3.229477e+00 \n","Epoch 510/1000, train_loss: 7.886538e-04, val_loss: 3.278149e+00 \n","Epoch 512/1000, train_loss: 8.127331e-04, val_loss: 3.210197e+00 \n","Epoch 514/1000, train_loss: 7.965142e-04, val_loss: 3.609053e+00 \n","Epoch 516/1000, train_loss: 7.854225e-04, val_loss: 3.251796e+00 \n","Epoch 518/1000, train_loss: 8.101255e-04, val_loss: 3.161928e+00 \n","Epoch 520/1000, train_loss: 7.799705e-04, val_loss: 3.315444e+00 \n","Epoch 522/1000, train_loss: 7.852518e-04, val_loss: 3.275227e+00 \n","Epoch 524/1000, train_loss: 8.106961e-04, val_loss: 3.290702e+00 \n","Epoch 526/1000, train_loss: 7.962341e-04, val_loss: 3.192817e+00 \n","Epoch 528/1000, train_loss: 7.829013e-04, val_loss: 3.151788e+00 \n","Epoch 530/1000, train_loss: 7.901588e-04, val_loss: 3.156854e+00 \n","Epoch 532/1000, train_loss: 7.787073e-04, val_loss: 3.190625e+00 \n","Epoch 534/1000, train_loss: 8.082099e-04, val_loss: 3.210153e+00 \n","Epoch 536/1000, train_loss: 7.795155e-04, val_loss: 3.204407e+00 \n","Epoch 538/1000, train_loss: 8.215317e-04, val_loss: 3.257273e+00 \n","Epoch 540/1000, train_loss: 7.772019e-04, val_loss: 3.175366e+00 \n","Epoch 542/1000, train_loss: 9.063612e-04, val_loss: 3.174526e+00 \n","Epoch 544/1000, train_loss: 7.989906e-04, val_loss: 3.311816e+00 \n","Epoch 546/1000, train_loss: 7.901427e-04, val_loss: 3.185690e+00 \n","Epoch 548/1000, train_loss: 7.756095e-04, val_loss: 3.260880e+00 \n","Epoch 550/1000, train_loss: 7.791231e-04, val_loss: 3.257282e+00 \n","Epoch 552/1000, train_loss: 7.895361e-04, val_loss: 3.483396e+00 \n","Epoch 554/1000, train_loss: 7.699020e-04, val_loss: 3.241067e+00 \n","Epoch 556/1000, train_loss: 8.007224e-04, val_loss: 3.451812e+00 \n","Epoch 558/1000, train_loss: 8.127740e-04, val_loss: 3.244755e+00 \n","Epoch 560/1000, train_loss: 7.735503e-04, val_loss: 3.258188e+00 \n","Epoch 562/1000, train_loss: 7.849791e-04, val_loss: 3.164676e+00 \n","Epoch 564/1000, train_loss: 7.790719e-04, val_loss: 3.163114e+00 \n","Epoch 566/1000, train_loss: 7.675197e-04, val_loss: 3.308919e+00 \n","Epoch 568/1000, train_loss: 7.878875e-04, val_loss: 3.153158e+00 \n","Epoch 570/1000, train_loss: 7.773246e-04, val_loss: 3.190610e+00 \n","Epoch 572/1000, train_loss: 7.744703e-04, val_loss: 3.192870e+00 \n","Epoch 574/1000, train_loss: 7.831438e-04, val_loss: 3.283560e+00 \n","Epoch 576/1000, train_loss: 8.611292e-04, val_loss: 3.325438e+00 \n","Epoch 578/1000, train_loss: 8.464328e-04, val_loss: 3.221697e+00 \n","Epoch 580/1000, train_loss: 7.820897e-04, val_loss: 3.449846e+00 \n","Epoch 582/1000, train_loss: 7.815171e-04, val_loss: 3.226474e+00 \n","Epoch 584/1000, train_loss: 7.839597e-04, val_loss: 3.182267e+00 \n","Epoch 586/1000, train_loss: 7.658306e-04, val_loss: 3.233065e+00 \n","Epoch 588/1000, train_loss: 7.741843e-04, val_loss: 3.174882e+00 \n","Epoch 590/1000, train_loss: 7.745693e-04, val_loss: 3.209650e+00 \n","Epoch 592/1000, train_loss: 7.770049e-04, val_loss: 3.254185e+00 \n","Epoch 594/1000, train_loss: 7.883968e-04, val_loss: 3.326299e+00 \n","Epoch 596/1000, train_loss: 7.702172e-04, val_loss: 3.163119e+00 \n","Epoch 598/1000, train_loss: 7.728352e-04, val_loss: 3.281589e+00 \n","Epoch 600/1000, train_loss: 7.922200e-04, val_loss: 3.167348e+00 \n","Epoch 602/1000, train_loss: 7.878346e-04, val_loss: 3.163480e+00 \n","Epoch 604/1000, train_loss: 7.910924e-04, val_loss: 3.160832e+00 \n","Epoch 606/1000, train_loss: 9.449702e-04, val_loss: 3.226852e+00 \n","Epoch 608/1000, train_loss: 7.838794e-04, val_loss: 3.394812e+00 \n","Epoch 610/1000, train_loss: 7.941984e-04, val_loss: 3.178125e+00 \n","Epoch 612/1000, train_loss: 7.826079e-04, val_loss: 3.301926e+00 \n","Epoch 614/1000, train_loss: 7.844474e-04, val_loss: 3.403172e+00 \n","Epoch 616/1000, train_loss: 8.106560e-04, val_loss: 3.161155e+00 \n","Epoch 618/1000, train_loss: 7.880613e-04, val_loss: 3.166225e+00 \n","Epoch 620/1000, train_loss: 7.766296e-04, val_loss: 3.204837e+00 \n","Epoch 622/1000, train_loss: 7.755824e-04, val_loss: 3.237042e+00 \n","Epoch 624/1000, train_loss: 7.842817e-04, val_loss: 3.249946e+00 \n","Epoch 626/1000, train_loss: 7.723038e-04, val_loss: 3.432254e+00 \n","Epoch 628/1000, train_loss: 9.089800e-04, val_loss: 3.347103e+00 \n","Epoch 630/1000, train_loss: 7.874390e-04, val_loss: 3.537327e+00 \n","Epoch 632/1000, train_loss: 7.667745e-04, val_loss: 3.551615e+00 \n","Epoch 634/1000, train_loss: 7.682287e-04, val_loss: 3.299962e+00 \n","Epoch 636/1000, train_loss: 7.680785e-04, val_loss: 3.173660e+00 \n","Epoch 638/1000, train_loss: 7.613231e-04, val_loss: 3.234683e+00 \n","Epoch 640/1000, train_loss: 7.644195e-04, val_loss: 3.206774e+00 \n","Epoch 642/1000, train_loss: 7.861382e-04, val_loss: 3.344289e+00 \n","Epoch 644/1000, train_loss: 7.699860e-04, val_loss: 3.179582e+00 \n","Epoch 646/1000, train_loss: 7.716542e-04, val_loss: 3.204511e+00 \n","Epoch 648/1000, train_loss: 7.835237e-04, val_loss: 3.156118e+00 \n","Epoch 650/1000, train_loss: 7.782228e-04, val_loss: 3.263482e+00 \n","Epoch 652/1000, train_loss: 7.589757e-04, val_loss: 3.190286e+00 \n","Epoch 654/1000, train_loss: 7.754915e-04, val_loss: 3.292837e+00 \n","Epoch 656/1000, train_loss: 7.723566e-04, val_loss: 3.179399e+00 \n","Epoch 658/1000, train_loss: 7.710942e-04, val_loss: 3.177482e+00 \n","Epoch 660/1000, train_loss: 7.666686e-04, val_loss: 3.467715e+00 \n","Epoch 662/1000, train_loss: 7.775055e-04, val_loss: 3.671577e+00 \n","Epoch 664/1000, train_loss: 7.716753e-04, val_loss: 3.267878e+00 \n","Epoch 666/1000, train_loss: 7.579383e-04, val_loss: 3.340418e+00 \n","Epoch 668/1000, train_loss: 7.877745e-04, val_loss: 3.178442e+00 \n","Epoch 670/1000, train_loss: 7.851630e-04, val_loss: 3.337248e+00 \n","Epoch 672/1000, train_loss: 7.991471e-04, val_loss: 3.161525e+00 \n","Epoch 674/1000, train_loss: 7.698344e-04, val_loss: 3.384937e+00 \n","Epoch 676/1000, train_loss: 7.705344e-04, val_loss: 3.161734e+00 \n","Epoch 678/1000, train_loss: 8.064592e-04, val_loss: 3.237441e+00 \n","Epoch 680/1000, train_loss: 8.055105e-04, val_loss: 3.241388e+00 \n","Epoch 682/1000, train_loss: 7.584566e-04, val_loss: 3.220001e+00 \n","Epoch 684/1000, train_loss: 7.692386e-04, val_loss: 3.192354e+00 \n","Epoch 686/1000, train_loss: 7.504343e-04, val_loss: 3.259036e+00 \n","Epoch 688/1000, train_loss: 7.712478e-04, val_loss: 3.199575e+00 \n","Epoch 690/1000, train_loss: 8.244966e-04, val_loss: 3.343367e+00 \n","Epoch 692/1000, train_loss: 7.668954e-04, val_loss: 3.195244e+00 \n","Epoch 694/1000, train_loss: 7.579477e-04, val_loss: 3.170968e+00 \n","Epoch 696/1000, train_loss: 7.790481e-04, val_loss: 3.243080e+00 \n","Epoch 698/1000, train_loss: 7.762526e-04, val_loss: 3.168926e+00 \n","Epoch 700/1000, train_loss: 7.686665e-04, val_loss: 3.188126e+00 \n","Epoch 702/1000, train_loss: 7.704490e-04, val_loss: 3.174922e+00 \n","Epoch 704/1000, train_loss: 7.647753e-04, val_loss: 3.209483e+00 \n","Epoch 706/1000, train_loss: 7.762094e-04, val_loss: 3.172749e+00 \n","Epoch 708/1000, train_loss: 7.755029e-04, val_loss: 3.422095e+00 \n","Epoch 710/1000, train_loss: 7.565976e-04, val_loss: 3.172017e+00 \n","Epoch 712/1000, train_loss: 7.635446e-04, val_loss: 3.159337e+00 \n","Epoch 714/1000, train_loss: 7.712223e-04, val_loss: 3.261736e+00 \n","Epoch 716/1000, train_loss: 7.738421e-04, val_loss: 3.206926e+00 \n","Epoch 718/1000, train_loss: 7.694707e-04, val_loss: 3.273396e+00 \n","Epoch 720/1000, train_loss: 7.716395e-04, val_loss: 3.233184e+00 \n","Epoch 722/1000, train_loss: 7.660802e-04, val_loss: 3.227786e+00 \n","Epoch 724/1000, train_loss: 7.610062e-04, val_loss: 3.312214e+00 \n","Epoch 726/1000, train_loss: 7.699750e-04, val_loss: 3.339461e+00 \n","Epoch 728/1000, train_loss: 7.716016e-04, val_loss: 3.241807e+00 \n","Epoch 730/1000, train_loss: 8.113573e-04, val_loss: 3.208435e+00 \n","Epoch 732/1000, train_loss: 7.792951e-04, val_loss: 3.391341e+00 \n","Epoch 734/1000, train_loss: 7.531006e-04, val_loss: 3.182832e+00 \n","Epoch 736/1000, train_loss: 8.233941e-04, val_loss: 3.185294e+00 \n","Epoch 738/1000, train_loss: 7.507588e-04, val_loss: 3.238792e+00 \n","Epoch 740/1000, train_loss: 7.666997e-04, val_loss: 3.163844e+00 \n","Epoch 742/1000, train_loss: 7.710680e-04, val_loss: 3.198281e+00 \n","Epoch 744/1000, train_loss: 7.568324e-04, val_loss: 3.258425e+00 \n","Epoch 746/1000, train_loss: 7.412891e-04, val_loss: 3.222206e+00 \n","Epoch 748/1000, train_loss: 7.715945e-04, val_loss: 3.165810e+00 \n","Epoch 750/1000, train_loss: 7.787989e-04, val_loss: 3.240188e+00 \n","Epoch 752/1000, train_loss: 7.920987e-04, val_loss: 3.186109e+00 \n","Epoch 754/1000, train_loss: 7.437966e-04, val_loss: 3.170778e+00 \n","Epoch 756/1000, train_loss: 7.671906e-04, val_loss: 3.221948e+00 \n","Epoch 758/1000, train_loss: 7.959640e-04, val_loss: 3.277282e+00 \n","Epoch 760/1000, train_loss: 7.667453e-04, val_loss: 3.225125e+00 \n","Epoch 762/1000, train_loss: 8.188985e-04, val_loss: 3.393714e+00 \n","Epoch 764/1000, train_loss: 7.567955e-04, val_loss: 3.185011e+00 \n","Epoch 766/1000, train_loss: 7.557238e-04, val_loss: 3.183703e+00 \n","Epoch 768/1000, train_loss: 7.619396e-04, val_loss: 3.220708e+00 \n","Epoch 770/1000, train_loss: 7.539130e-04, val_loss: 3.172831e+00 \n","Epoch 772/1000, train_loss: 7.462205e-04, val_loss: 3.213946e+00 \n","Epoch 774/1000, train_loss: 7.456018e-04, val_loss: 3.212120e+00 \n","Epoch 776/1000, train_loss: 7.473140e-04, val_loss: 3.332820e+00 \n","Epoch 778/1000, train_loss: 7.584298e-04, val_loss: 3.249091e+00 \n","Epoch 780/1000, train_loss: 7.577252e-04, val_loss: 3.309570e+00 \n","Epoch 782/1000, train_loss: 7.629214e-04, val_loss: 3.197481e+00 \n","Epoch 784/1000, train_loss: 7.704392e-04, val_loss: 3.311932e+00 \n","Epoch 786/1000, train_loss: 8.498812e-04, val_loss: 3.250067e+00 \n","Epoch 788/1000, train_loss: 7.426787e-04, val_loss: 3.190831e+00 \n","Epoch 790/1000, train_loss: 7.486220e-04, val_loss: 3.401357e+00 \n","Epoch 792/1000, train_loss: 7.308108e-04, val_loss: 3.151855e+00 \n","Epoch 794/1000, train_loss: 7.619197e-04, val_loss: 3.489937e+00 \n","Epoch 796/1000, train_loss: 7.438398e-04, val_loss: 3.266633e+00 \n","Epoch 798/1000, train_loss: 7.474947e-04, val_loss: 3.172966e+00 \n","Epoch 800/1000, train_loss: 7.596657e-04, val_loss: 3.225095e+00 \n","Epoch 802/1000, train_loss: 7.409653e-04, val_loss: 3.310038e+00 \n","Epoch 804/1000, train_loss: 7.576062e-04, val_loss: 3.315502e+00 \n","Epoch 806/1000, train_loss: 7.773040e-04, val_loss: 3.264213e+00 \n","Epoch 808/1000, train_loss: 7.803741e-04, val_loss: 3.291136e+00 \n","Epoch 810/1000, train_loss: 7.539598e-04, val_loss: 3.318749e+00 \n","Epoch 812/1000, train_loss: 7.473508e-04, val_loss: 3.545686e+00 \n","Epoch 814/1000, train_loss: 7.652554e-04, val_loss: 3.283753e+00 \n","Epoch 816/1000, train_loss: 7.608362e-04, val_loss: 3.221527e+00 \n","Epoch 818/1000, train_loss: 7.744722e-04, val_loss: 3.212445e+00 \n","Epoch 820/1000, train_loss: 7.617543e-04, val_loss: 3.296731e+00 \n","Epoch 822/1000, train_loss: 7.441791e-04, val_loss: 3.167612e+00 \n","Epoch 824/1000, train_loss: 7.604670e-04, val_loss: 3.200349e+00 \n","Epoch 826/1000, train_loss: 7.532600e-04, val_loss: 3.314034e+00 \n","Epoch 828/1000, train_loss: 7.888886e-04, val_loss: 3.237668e+00 \n","Epoch 830/1000, train_loss: 7.461060e-04, val_loss: 3.200217e+00 \n","Epoch 832/1000, train_loss: 7.523527e-04, val_loss: 3.502892e+00 \n","Epoch 834/1000, train_loss: 7.605364e-04, val_loss: 3.268626e+00 \n","Epoch 836/1000, train_loss: 7.543956e-04, val_loss: 3.253679e+00 \n","Epoch 838/1000, train_loss: 7.567098e-04, val_loss: 3.187553e+00 \n","Epoch 840/1000, train_loss: 7.552581e-04, val_loss: 3.161375e+00 \n","Epoch 842/1000, train_loss: 7.486367e-04, val_loss: 3.165020e+00 \n","Epoch 844/1000, train_loss: 7.537743e-04, val_loss: 3.242924e+00 \n","Epoch 846/1000, train_loss: 7.785103e-04, val_loss: 3.461175e+00 \n","Epoch 848/1000, train_loss: 7.565670e-04, val_loss: 3.200927e+00 \n","Epoch 850/1000, train_loss: 7.781937e-04, val_loss: 3.469231e+00 \n","Epoch 852/1000, train_loss: 7.580754e-04, val_loss: 3.210384e+00 \n","Epoch 854/1000, train_loss: 7.470816e-04, val_loss: 3.193493e+00 \n","Epoch 856/1000, train_loss: 7.732014e-04, val_loss: 3.169825e+00 \n","Epoch 858/1000, train_loss: 7.671344e-04, val_loss: 3.156631e+00 \n","Epoch 860/1000, train_loss: 7.639240e-04, val_loss: 3.158104e+00 \n","Epoch 862/1000, train_loss: 7.346446e-04, val_loss: 3.406653e+00 \n","Epoch 864/1000, train_loss: 7.623107e-04, val_loss: 3.174385e+00 \n","Epoch 866/1000, train_loss: 7.638647e-04, val_loss: 3.157338e+00 \n","Epoch 868/1000, train_loss: 7.429869e-04, val_loss: 3.169168e+00 \n","Epoch 870/1000, train_loss: 7.477488e-04, val_loss: 3.189683e+00 \n","Epoch 872/1000, train_loss: 7.454249e-04, val_loss: 3.208950e+00 \n","Epoch 874/1000, train_loss: 7.438425e-04, val_loss: 3.336392e+00 \n","Epoch 876/1000, train_loss: 7.353197e-04, val_loss: 3.220597e+00 \n","Epoch 878/1000, train_loss: 7.367258e-04, val_loss: 3.265448e+00 \n","Epoch 880/1000, train_loss: 7.525464e-04, val_loss: 3.259261e+00 \n","Epoch 882/1000, train_loss: 7.520243e-04, val_loss: 3.194390e+00 \n","Epoch 884/1000, train_loss: 7.510893e-04, val_loss: 3.233507e+00 \n","Epoch 886/1000, train_loss: 7.897426e-04, val_loss: 3.494745e+00 \n","Epoch 888/1000, train_loss: 7.548012e-04, val_loss: 3.163281e+00 \n","Epoch 890/1000, train_loss: 7.515951e-04, val_loss: 3.371536e+00 \n","Epoch 892/1000, train_loss: 7.866721e-04, val_loss: 3.156291e+00 \n","Epoch 894/1000, train_loss: 7.480663e-04, val_loss: 3.264082e+00 \n","Epoch 896/1000, train_loss: 7.639503e-04, val_loss: 3.172138e+00 \n","Epoch 898/1000, train_loss: 7.396099e-04, val_loss: 3.544043e+00 \n","Epoch 900/1000, train_loss: 7.286153e-04, val_loss: 3.157424e+00 \n","Epoch 902/1000, train_loss: 7.446753e-04, val_loss: 3.163900e+00 \n","Epoch 904/1000, train_loss: 7.292598e-04, val_loss: 3.333559e+00 \n","Epoch 906/1000, train_loss: 7.712792e-04, val_loss: 3.172418e+00 \n","Epoch 908/1000, train_loss: 7.858279e-04, val_loss: 3.175387e+00 \n","Epoch 910/1000, train_loss: 7.520515e-04, val_loss: 3.361586e+00 \n","Epoch 912/1000, train_loss: 7.557069e-04, val_loss: 3.152969e+00 \n","Epoch 914/1000, train_loss: 7.342427e-04, val_loss: 3.166228e+00 \n","Epoch 916/1000, train_loss: 7.265794e-04, val_loss: 3.669942e+00 \n","Epoch 918/1000, train_loss: 7.437081e-04, val_loss: 3.378821e+00 \n","Epoch 920/1000, train_loss: 7.449216e-04, val_loss: 3.194575e+00 \n","Epoch 922/1000, train_loss: 7.776095e-04, val_loss: 3.153566e+00 \n","Epoch 924/1000, train_loss: 7.633268e-04, val_loss: 3.365685e+00 \n","Epoch 926/1000, train_loss: 7.505035e-04, val_loss: 3.160187e+00 \n","Epoch 928/1000, train_loss: 7.229057e-04, val_loss: 3.488064e+00 \n","Epoch 930/1000, train_loss: 7.390644e-04, val_loss: 3.191052e+00 \n","Epoch 932/1000, train_loss: 7.550608e-04, val_loss: 3.259116e+00 \n","Epoch 934/1000, train_loss: 7.392992e-04, val_loss: 3.157610e+00 \n","Epoch 936/1000, train_loss: 7.922380e-04, val_loss: 3.161278e+00 \n","Epoch 938/1000, train_loss: 7.297403e-04, val_loss: 3.170380e+00 \n","Epoch 940/1000, train_loss: 7.401902e-04, val_loss: 3.237900e+00 \n","Epoch 942/1000, train_loss: 7.430852e-04, val_loss: 3.507033e+00 \n","Epoch 944/1000, train_loss: 7.799308e-04, val_loss: 3.600530e+00 \n","Epoch 946/1000, train_loss: 7.346201e-04, val_loss: 3.217529e+00 \n","Epoch 948/1000, train_loss: 7.439254e-04, val_loss: 3.188724e+00 \n","Epoch 950/1000, train_loss: 7.379572e-04, val_loss: 3.174688e+00 \n","Epoch 952/1000, train_loss: 7.359578e-04, val_loss: 3.160670e+00 \n","Epoch 954/1000, train_loss: 7.332667e-04, val_loss: 3.300478e+00 \n","Epoch 956/1000, train_loss: 7.328209e-04, val_loss: 3.270511e+00 \n","Epoch 958/1000, train_loss: 7.373220e-04, val_loss: 3.280682e+00 \n","Epoch 960/1000, train_loss: 7.367094e-04, val_loss: 3.590134e+00 \n","Epoch 962/1000, train_loss: 7.360048e-04, val_loss: 3.231702e+00 \n","Epoch 964/1000, train_loss: 7.359617e-04, val_loss: 3.193566e+00 \n","Epoch 966/1000, train_loss: 7.378841e-04, val_loss: 3.280627e+00 \n","Epoch 968/1000, train_loss: 7.324561e-04, val_loss: 3.188935e+00 \n","Epoch 970/1000, train_loss: 7.327815e-04, val_loss: 3.278511e+00 \n","Epoch 972/1000, train_loss: 7.229652e-04, val_loss: 3.323631e+00 \n","Epoch 974/1000, train_loss: 7.499800e-04, val_loss: 3.271728e+00 \n","Epoch 976/1000, train_loss: 7.374874e-04, val_loss: 3.323069e+00 \n","Epoch 978/1000, train_loss: 7.229044e-04, val_loss: 3.391598e+00 \n","Epoch 980/1000, train_loss: 7.990019e-04, val_loss: 3.172405e+00 \n","Epoch 982/1000, train_loss: 7.394840e-04, val_loss: 3.203738e+00 \n","Epoch 984/1000, train_loss: 7.271030e-04, val_loss: 3.237042e+00 \n","Epoch 986/1000, train_loss: 7.140779e-04, val_loss: 3.166106e+00 \n","Epoch 988/1000, train_loss: 7.252161e-04, val_loss: 3.245480e+00 \n","Epoch 990/1000, train_loss: 7.509128e-04, val_loss: 3.190649e+00 \n","Epoch 992/1000, train_loss: 7.318474e-04, val_loss: 3.163464e+00 \n","Epoch 994/1000, train_loss: 7.341697e-04, val_loss: 3.220707e+00 \n","Epoch 996/1000, train_loss: 7.282039e-04, val_loss: 3.190201e+00 \n","Epoch 998/1000, train_loss: 7.430116e-04, val_loss: 3.326091e+00 \n","Epoch 1000/1000, train_loss: 7.457730e-04, val_loss: 3.403598e+00 \n","FINISH.\n"]}],"source":["# start the main training process\n","max_epochs = 1000\n","print('train_data',len(train_data))\n","num_trainbatch = np.ceil(len(train_data)/256) \n","num_valbatch = np.ceil(len(val_data)/256) \n","train_history = []\n","val_history = []\n","\n","min_loss = 100000\n","current_patience = 0\n","patience = 5\n","\n","print('Start training!')\n","\n","for epoch in range(max_epochs): \n","    train_loss = run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=train_loader,\n","                           iftrain=True)\n","    train_history.append(train_loss/num_trainbatch)\n","    val_loss =  run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=val_loader,\n","                           iftrain=False)\n","    val_history.append(val_loss/num_valbatch)\n","    if epoch % 2 == 1:\n","      print(f\"Epoch {epoch + 1: >3}/{max_epochs}, train_loss: %e, val_loss: %e \"% \n","          (train_loss/num_trainbatch, val_loss/num_valbatch))\n","'''\n","    # early stopping\n","    if min_loss == 100000 or val_loss < min_loss :\n","        min_loss = val_loss\n","        current_patience = 0\n","        torch.save(mynet.state_dict(),'mynet.pth')\n","      \n","    else :\n","        current_patience += 1 \n","        if current_patience >= patience :\n","            print(\"Stopping early at epoch {}!\".format(epoch+1)) \n","            break   '''\n","\n","print('FINISH.')"],"id":"b784ca9a"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":1192,"status":"ok","timestamp":1642780985356,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"e880c2ea","outputId":"b751dcd4-f55c-41d7-f362-245b6f35b403"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# plot the train&validation loss curve \n","epochs = range(len(train_history))\n","plt.figure()\n","plt.plot(epochs, train_history, 'bo', label='Training loss')\n","#plt.plot(epochs, val_history, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","\n","plt.legend()\n","plt.show()\n"],"id":"e880c2ea"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e02af27"},"outputs":[],"source":["# save trained model\n","torch.save(mynet.state_dict(),'/content/drive/My Drive/model/mynet2_10.pth')"],"id":"0e02af27"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1642711861530,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"3062832d","outputId":"59715e1d-0b9e-4675-cd54-9926c9598d24"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":188,"metadata":{},"output_type":"execute_result"}],"source":["mynet.load_state_dict(torch.load('/content/drive/My Drive/model/mynet2_4.pth'))"],"id":"3062832d"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":723,"status":"ok","timestamp":1642780989729,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"c070c8a6","outputId":"581a1547-ebcf-4d8c-dfb7-251e980d2710"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]},{"output_type":"stream","name":"stdout","text":["test 0\n","prediction  : tensor([[-0.0051, -0.0307]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 3.8322e-14, -2.4431e-02], device='cuda:0', dtype=torch.float64)\n","test 1\n","prediction  : tensor([[ 0.0014, -0.0521]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 7.6854e-14, -4.4376e-02], device='cuda:0', dtype=torch.float64)\n","test 2\n","prediction  : tensor([[ 0.9995, -0.0195]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.0243], device='cuda:0', dtype=torch.float64)\n","test 3\n","prediction  : tensor([[0.6516, 0.0921]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 0.6759, -0.0190], device='cuda:0', dtype=torch.float64)\n","test 4\n","prediction  : tensor([[ 0.7912, -0.0080]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 0.7330, -0.0099], device='cuda:0', dtype=torch.float64)\n","test 5\n","prediction  : tensor([[ 0.0324, -0.1099]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 7.0853e-18, -2.2659e-01], device='cuda:0', dtype=torch.float64)\n","test 6\n","prediction  : tensor([[-0.0014,  0.0301]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([0.0000, 0.0344], device='cuda:0', dtype=torch.float64)\n","test 7\n","prediction  : tensor([[0.4037, 0.5732]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([0.5808, 0.5255], device='cuda:0', dtype=torch.float64)\n","test 8\n","prediction  : tensor([[ 0.6755, -0.0500]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 0.6331, -0.0286], device='cuda:0', dtype=torch.float64)\n","test 9\n","prediction  : tensor([[0.2111, 0.0013]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 0.2069, -0.0007], device='cuda:0', dtype=torch.float64)\n","test 10\n","prediction  : tensor([[-0.0013, -0.1297]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0132e-12, -4.2688e-02], device='cuda:0', dtype=torch.float64)\n","test 11\n","prediction  : tensor([[ 0.0189, -0.1593]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 2.1360e-13, -5.1208e-01], device='cuda:0', dtype=torch.float64)\n","test 12\n","prediction  : tensor([[ 0.9670, -0.1406]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.2641], device='cuda:0', dtype=torch.float64)\n","test 13\n","prediction  : tensor([[ 0.0002, -0.0022]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 2.5759e-12, -9.8757e-03], device='cuda:0', dtype=torch.float64)\n","test 14\n","prediction  : tensor([[0.6557, 0.0600]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([0.6561, 0.0661], device='cuda:0', dtype=torch.float64)\n","test 15\n","prediction  : tensor([[ 0.1520, -0.0434]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 0.1549, -0.0427], device='cuda:0', dtype=torch.float64)\n","test 16\n","prediction  : tensor([[0.7359, 0.0635]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 0.7352, -0.0833], device='cuda:0', dtype=torch.float64)\n","test 17\n","prediction  : tensor([[0.9584, 0.1718]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.0000, 0.1797], device='cuda:0', dtype=torch.float64)\n","test 18\n","prediction  : tensor([[1.0264, 0.2798]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.0000, 0.0498], device='cuda:0', dtype=torch.float64)\n","test 19\n","prediction  : tensor([[0.9949, 0.9143]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.4490], device='cuda:0', dtype=torch.float64)\n","test 0\n","prediction  : tensor([[ 0.0337, -0.0038]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.1605e-16, 4.5492e-03], device='cuda:0', dtype=torch.float64)\n","test 1\n","prediction  : tensor([[ 0.7347, -0.0351]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([0.7226, 0.0021], device='cuda:0', dtype=torch.float64)\n","test 2\n","prediction  : tensor([[0.0769, 0.0115]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([0.0915, 0.0244], device='cuda:0', dtype=torch.float64)\n","test 3\n","prediction  : tensor([[-0.0004, -0.0118]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.5137e-13, -5.1377e-03], device='cuda:0', dtype=torch.float64)\n","test 4\n","prediction  : tensor([[ 0.9981, -0.0194]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.0152], device='cuda:0', dtype=torch.float64)\n","test 5\n","prediction  : tensor([[ 1.0021, -0.0074]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.0016], device='cuda:0', dtype=torch.float64)\n","test 6\n","prediction  : tensor([[1.0016, 0.5628]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.0000, 0.5523], device='cuda:0', dtype=torch.float64)\n","test 7\n","prediction  : tensor([[0.9999, 0.5246]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.0000, 0.5274], device='cuda:0', dtype=torch.float64)\n","test 8\n","prediction  : tensor([[ 1.0064, -0.0020]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.0000, 0.0025], device='cuda:0', dtype=torch.float64)\n","test 9\n","prediction  : tensor([[ 1.0051, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.6834], device='cuda:0', dtype=torch.float64)\n","test 10\n","prediction  : tensor([[ 0.9507, -0.9984]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1., -1.], device='cuda:0', dtype=torch.float64)\n","test 11\n","prediction  : tensor([[ 0.3113, -0.0112]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 0.2942, -0.0164], device='cuda:0', dtype=torch.float64)\n","test 12\n","prediction  : tensor([[ 0.9999, -0.1816]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.1632], device='cuda:0', dtype=torch.float64)\n","test 13\n","prediction  : tensor([[-0.0023, -0.0247]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.7021e-17, -3.1374e-02], device='cuda:0', dtype=torch.float64)\n","test 14\n","prediction  : tensor([[0.1143, 0.0429]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([0.0005, 0.0466], device='cuda:0', dtype=torch.float64)\n","test 15\n","prediction  : tensor([[-0.0061, -0.0247]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([5.7015e-16, 1.2230e-02], device='cuda:0', dtype=torch.float64)\n","test 16\n","prediction  : tensor([[0.9232, 0.7164]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.0000, 0.6899], device='cuda:0', dtype=torch.float64)\n","test 17\n","prediction  : tensor([[1.0067, 0.0234]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([1.0000, 0.0157], device='cuda:0', dtype=torch.float64)\n","test 18\n","prediction  : tensor([[ 0.9958, -0.1519]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.4296], device='cuda:0', dtype=torch.float64)\n","test 19\n","prediction  : tensor([[ 0.9967, -0.0047]], device='cuda:0', grad_fn=<DivBackward0>),\n","ground truth：tensor([ 1.0000, -0.0103], device='cuda:0', dtype=torch.float64)\n"]}],"source":["# test inference \n","test_loss = 0\n","for n, data in enumerate(test_loader): \n","        X = torch.tensor(data[0]).cuda() \n","        y = torch.tensor(data[1]).cuda()\n","        if n < 2:\n","          for i, x in enumerate(X): \n","            mynet.eval()\n","            x = x[None, :]\n","            y_pred = mynet(x.to(torch.float32)) \n","            if i < 20:\n","              print('test',i)\n","              print('prediction  : {},\\nground truth：{}'.format(y_pred/10, y[i]/10)) \n","              "],"id":"c070c8a6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"296dfbd2"},"outputs":[],"source":[""],"id":"296dfbd2"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"train_model2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}