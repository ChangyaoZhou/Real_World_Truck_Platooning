{"cells":[{"cell_type":"markdown","metadata":{"id":"a66201df"},"source":["### 1 Loading Dataset"],"id":"a66201df"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22026,"status":"ok","timestamp":1643755332741,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"_R6k7PwWZOQx","outputId":"e7629b61-025c-4f8e-905b-1c88fa841838"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import sys\n","import os\n","\n","drive.mount('/content/drive')\n","sys.path.insert(0,'/content/drive/My Drive/Project/model1and2/')"],"id":"_R6k7PwWZOQx"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210,"status":"ok","timestamp":1643023796875,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"DvUpvjvtooKI","outputId":"6742f909-54a5-4892-8415-f7e96bf812bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Jan 24 11:29:56 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!/opt/bin/nvidia-smi"],"id":"DvUpvjvtooKI"},{"cell_type":"code","execution_count":2,"metadata":{"id":"7a91843a","executionInfo":{"status":"ok","timestamp":1643755350349,"user_tz":-60,"elapsed":8506,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}}},"outputs":[],"source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","\n","from my_datasets import MyDataset\n","from my_models import MyModel\n","from data.delta_all_degree import delta_data_degree\n","from data.delta_all import delta_data\n","# [delta_x, delta_y, delta_theta, v_ref, v_ego, throttle, str_angle]"],"id":"7a91843a"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":335,"status":"ok","timestamp":1643755358878,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"97636c30"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"],"id":"97636c30"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1643755360174,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"8ea6d0e6","outputId":"754bbef5-86af-4c10-cc04-2bb367d1d292"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(torch.cuda.is_available())\n","print(device)"],"id":"8ea6d0e6"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1643755395432,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"5b935cb0","outputId":"47173f32-fd1d-4885-fc13-5649ddb4323d"},"outputs":[{"output_type":"stream","name":"stdout","text":["train input shape (50470, 5)\n"]}],"source":["def split_dataset(data, split_list):\n","    #print(data.shape)\n","    split_num = data.shape[0] * np.array(split_list)\n","    #print(split_num)\n","    return data[:round(split_num[0]), :], data[round(split_num[0]):round(split_num[1]+split_num[0]), :], data[round(split_num[1]+split_num[0]):, :]\n"," \n","np.random.shuffle(delta_data) \n","split_list = [0.8, 0.1, 0.1]\n","train_input, val_input, test_input = split_dataset(delta_data[:, :5], split_list)\n","train_label, val_label, test_label = split_dataset(delta_data[:, 5:], split_list) \n","print('train input shape', train_input.shape)"],"id":"5b935cb0"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1643755408407,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"e5f15563","outputId":"37791a91-d1b1-49d5-8dba-94b98a578219"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train size: 50470\n","Validation size: 6309\n","Test size: 6309\n","Input size:  (5,)\n","Label size:  (2,)\n","(array([-0.37481689,  7.01135254, -0.12250794,  4.93930436,  5.19257548]), array([ 0.01263191, -0.03249225]))\n"]}],"source":["# test_dataset with only one sample for overfitting\n","over_input = delta_data[:2, :5]\n","over_label = delta_data[:2, 5:]\n","\n","train_data = MyDataset(states = train_input, labels = train_label)\n","val_data = MyDataset(states = val_input, labels = val_label)\n","test_data = MyDataset(states = test_input, labels = test_label)\n","over_data = MyDataset(states = over_input, labels = over_label)   \n","\n","train_loader = DataLoader(dataset=train_data, batch_size=256, shuffle=True)\n","val_loader = DataLoader(dataset=val_data, batch_size=256, shuffle=True)\n","test_loader = DataLoader(dataset=test_data, batch_size=128, shuffle=True)\n","over_loader = DataLoader(dataset=over_data, batch_size=2, shuffle=True)\n","\n","print(\"Train size: %i\" % len(train_data))\n","print(\"Validation size: %i\" % len(val_data))\n","print(\"Test size: %i\" % len(test_data))\n","print(\"Input size: \", train_data[0][0].shape)\n","print(\"Label size: \", train_data[0][1].shape)\n","print(train_data[0])"],"id":"e5f15563"},{"cell_type":"markdown","metadata":{"id":"8b4f5b2d"},"source":["### 2 Defining Neural Network"],"id":"8b4f5b2d"},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643755607474,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"20a8445a","outputId":"c9d8b230-c2ab-43a7-e37b-97dc0d0ba663"},"outputs":[{"output_type":"stream","name":"stdout","text":["MyModel(\n","  (predictor): Sequential(\n","    (0): Linear(in_features=5, out_features=128, bias=True)\n","    (1): ReLU()\n","    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Linear(in_features=128, out_features=256, bias=True)\n","    (4): ReLU()\n","    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): Linear(in_features=256, out_features=512, bias=True)\n","    (7): ReLU()\n","    (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): Linear(in_features=512, out_features=256, bias=True)\n","    (10): ReLU()\n","    (11): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): Linear(in_features=256, out_features=128, bias=True)\n","    (13): ReLU()\n","    (14): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (15): Linear(in_features=128, out_features=2, bias=True)\n","  )\n",")\n"]}],"source":["mynet = MyModel(neurons = [128, 256, 512, 256, 128]) \n","print(mynet)"],"id":"20a8445a"},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1643755613103,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"484ee84f","outputId":"0b5d5d24-da9f-40bb-ef14-938c74cb7e42"},"outputs":[{"output_type":"stream","name":"stdout","text":["332,418 total parameters.\n","332,418 trainable parameters.\n"]}],"source":["total_params = sum(p.numel() for p in mynet.parameters())\n","print(f'{total_params:,} total parameters.')\n","total_trainable_params = sum(\n","    p.numel() for p in mynet.parameters() if p.requires_grad)\n","print(f'{total_trainable_params:,} trainable parameters.')"],"id":"484ee84f"},{"cell_type":"markdown","metadata":{"id":"78ba5bf4"},"source":["### 3 Training Neural network"],"id":"78ba5bf4"},{"cell_type":"code","execution_count":11,"metadata":{"id":"f2e32edb","executionInfo":{"status":"ok","timestamp":1643755439232,"user_tz":-60,"elapsed":313,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}}},"outputs":[],"source":["mycriterion = nn.MSELoss() \n","myoptimizer = optim.Adam(mynet.parameters(), lr=1e-4, eps = 1e-08) "],"id":"f2e32edb"},{"cell_type":"code","execution_count":12,"metadata":{"id":"3fae618d","scrolled":true,"executionInfo":{"status":"ok","timestamp":1643755441480,"user_tz":-60,"elapsed":310,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}}},"outputs":[],"source":["def run_epoch(model,criterion,optimizer,dataloader,iftrain):    \n","    running_loss = 0.0  \n","    \n","    #Iterating through the minibatches of the data\n","    for i, data in enumerate(dataloader, 0): \n","        X, y = data\n","        X = X.cuda()\n","        y = y.cuda()\n","        #print(i)\n","        if iftrain:  \n","            #model.train()\n","            optimizer.zero_grad()\n","            y_pred = model(X.to(torch.float32)) \n","            y_pred = y_pred.float()\n","            y_pred[:,1] = y_pred[:,1] * 2\n","            y[:,1] = y[:,1] * 2\n","            y = y.float() \n","            \n","            loss = criterion(y_pred, y)  \n","            loss.backward()             \n","            optimizer.step()            \n","            running_loss += loss.item() \n","        else:\n","            model.eval()\n","            y_pred = model(X.to(torch.float32))\n","            y_pred = y_pred.float()  \n","            y = y.float() \n","            y_pred[:,1] = y_pred[:,1] * 2\n","            y[:,1] = y[:,1] * 2\n","            loss = criterion(y_pred , y)  \n","            running_loss += loss.item()    \n","    return running_loss    "],"id":"3fae618d"},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5774,"status":"ok","timestamp":1643755449691,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"bf32e03a","outputId":"8ff9cfa8-cf40-4e29-d7bc-7de66a874e80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch  50/1000, train_loss: 7.225120e-06, val_loss: 2.700517e-05 \n","Epoch 100/1000, train_loss: 1.512069e-08, val_loss: 1.035509e-07 \n","Epoch 150/1000, train_loss: 7.335395e-09, val_loss: 5.747936e-09 \n","Epoch 200/1000, train_loss: 4.070927e-11, val_loss: 3.308124e-11 \n","Epoch 250/1000, train_loss: 1.453616e-13, val_loss: 1.273074e-13 \n","Epoch 300/1000, train_loss: 2.313796e-16, val_loss: 2.001112e-16 \n","Epoch 350/1000, train_loss: 4.185020e-17, val_loss: 4.449566e-17 \n","Epoch 400/1000, train_loss: 5.312591e-17, val_loss: 3.942159e-17 \n","Epoch 450/1000, train_loss: 5.867702e-17, val_loss: 4.202368e-17 \n","Epoch 500/1000, train_loss: 3.751340e-16, val_loss: 5.329938e-17 \n","Epoch 550/1000, train_loss: 5.629178e-17, val_loss: 3.782565e-16 \n","Epoch 600/1000, train_loss: 1.582935e-17, val_loss: 1.582935e-17 \n","Epoch 650/1000, train_loss: 2.607506e-17, val_loss: 3.002156e-17 \n","Epoch 700/1000, train_loss: 3.526910e-17, val_loss: 1.202380e-17 \n","Epoch 750/1000, train_loss: 4.868068e-18, val_loss: 1.440905e-17 \n","Epoch 800/1000, train_loss: 1.225148e-18, val_loss: 1.180696e-17 \n","Epoch 850/1000, train_loss: 2.828683e-17, val_loss: 5.968533e-17 \n","Epoch 900/1000, train_loss: 1.157169e-16, val_loss: 1.025764e-16 \n","Epoch 950/1000, train_loss: 4.737963e-18, val_loss: 9.215718e-19 \n","Epoch 1000/1000, train_loss: 5.170560e-17, val_loss: 3.075882e-17 \n"]}],"source":["# test if the model will overfit with only one sample\n","max_epochs = 1000 \n","train_history = []\n","val_history = []\n","\n","for epoch in range(max_epochs): \n","    train_loss = run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=over_loader,\n","                           iftrain=True)\n","    train_history.append(train_loss)\n","    val_loss =  run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=over_loader,\n","                           iftrain=False)\n","    val_history.append(val_loss)\n","    if epoch % 50 == 49:\n","        print(f\"Epoch {epoch + 1: >3}/{max_epochs}, train_loss: %2e, val_loss: %2e \"% \n","          (train_loss/5, val_loss/5))"],"id":"bf32e03a"},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1643755451719,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"6883ebae","outputId":"baaabbec-a7df-4d96-c7df-c08a1e71fa09"},"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[-2.7999, -8.7607,  0.0137,  4.9407,  5.5223],\n","        [-0.3748,  7.0114, -0.1225,  4.9393,  5.1926]], dtype=torch.float64), tensor([[ 1.0000,  0.0022],\n","        [ 0.0126, -0.0325]], dtype=torch.float64)]\n","test 0\n","prediction: tensor([[ 1.0000,  0.0022],\n","        [ 0.0126, -0.0325]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([[ 1.0000,  0.0022],\n","        [ 0.0126, -0.0325]], device='cuda:0', dtype=torch.float64)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]}],"source":["# test inference \n","for i, data in enumerate(over_loader, 0): \n","        print(data)\n","        X = torch.tensor(data[0]).cuda()\n","        y = torch.tensor(data[1]).cuda()\n","        y_pred = mynet(X.to(torch.float32))\n","        if i < 10:\n","            print('test',i)\n","            print('prediction: {},\\nground truth：{}'.format(y_pred, y)) "],"id":"6883ebae"},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1643755458310,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"93bdaf01","outputId":"b1ddef0f-ef4f-47dc-ccfd-07b9e59b1a50"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# plot the train&validation loss curve with only one sample\n","epochs = range(len(train_history))\n","plt.figure()\n","plt.plot(epochs, train_history, 'bo', label='Training loss')\n","plt.plot(epochs, val_history, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","\n","plt.legend()\n","plt.show()"],"id":"93bdaf01"},{"cell_type":"code","execution_count":null,"metadata":{"id":"03978b27"},"outputs":[],"source":["mycriterion = nn.MSELoss() \n","myoptimizer = optim.Adam(mynet.parameters(), lr=1e-3, eps = 1e-08) "],"id":"03978b27"},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b784ca9a","scrolled":true,"executionInfo":{"status":"ok","timestamp":1643756140892,"user_tz":-60,"elapsed":512121,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"}},"outputId":"6255931f-cc3e-4287-c678-d18b5755d339"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_data 50470\n","Start training!\n","Epoch   1/500, train_loss: 6.220157e-02, val_loss: 3.712287e-02 \n","Epoch   2/500, train_loss: 3.911550e-02, val_loss: 3.761246e-02 \n","Epoch   3/500, train_loss: 3.916942e-02, val_loss: 3.754624e-02 \n","Epoch   4/500, train_loss: 3.914755e-02, val_loss: 3.732341e-02 \n","Epoch   5/500, train_loss: 3.923287e-02, val_loss: 3.731794e-02 \n","Epoch   6/500, train_loss: 3.958222e-02, val_loss: 3.743652e-02 \n","Epoch   7/500, train_loss: 3.917401e-02, val_loss: 3.710474e-02 \n","Epoch   8/500, train_loss: 3.929286e-02, val_loss: 3.717915e-02 \n","Epoch   9/500, train_loss: 3.908027e-02, val_loss: 3.730908e-02 \n","Epoch  10/500, train_loss: 3.912909e-02, val_loss: 3.716164e-02 \n","Epoch  11/500, train_loss: 3.916292e-02, val_loss: 3.703963e-02 \n","Epoch  12/500, train_loss: 3.907758e-02, val_loss: 3.728372e-02 \n","Epoch  13/500, train_loss: 3.903596e-02, val_loss: 3.728382e-02 \n","Epoch  14/500, train_loss: 3.923272e-02, val_loss: 3.721283e-02 \n","Epoch  15/500, train_loss: 3.911233e-02, val_loss: 3.720123e-02 \n","Epoch  16/500, train_loss: 3.935423e-02, val_loss: 3.747788e-02 \n","Epoch  17/500, train_loss: 3.921596e-02, val_loss: 3.717439e-02 \n","Epoch  18/500, train_loss: 3.922245e-02, val_loss: 3.736306e-02 \n","Epoch  19/500, train_loss: 3.910750e-02, val_loss: 3.711523e-02 \n","Epoch  20/500, train_loss: 3.917314e-02, val_loss: 3.717341e-02 \n","Epoch  21/500, train_loss: 3.906169e-02, val_loss: 3.715245e-02 \n","Epoch  22/500, train_loss: 3.915057e-02, val_loss: 3.739582e-02 \n","Epoch  23/500, train_loss: 3.908274e-02, val_loss: 3.706240e-02 \n","Epoch  24/500, train_loss: 3.916876e-02, val_loss: 3.720363e-02 \n","Epoch  25/500, train_loss: 3.903754e-02, val_loss: 3.720796e-02 \n","Epoch  26/500, train_loss: 3.908790e-02, val_loss: 3.745904e-02 \n","Epoch  27/500, train_loss: 3.909996e-02, val_loss: 3.731784e-02 \n","Epoch  28/500, train_loss: 3.906780e-02, val_loss: 3.717628e-02 \n","Epoch  29/500, train_loss: 3.905088e-02, val_loss: 3.732378e-02 \n","Epoch  30/500, train_loss: 3.913519e-02, val_loss: 3.710479e-02 \n","Epoch  31/500, train_loss: 3.907249e-02, val_loss: 3.755888e-02 \n","Epoch  32/500, train_loss: 3.911311e-02, val_loss: 3.739160e-02 \n","Epoch  33/500, train_loss: 3.910795e-02, val_loss: 3.710815e-02 \n","Epoch  34/500, train_loss: 3.912059e-02, val_loss: 3.710779e-02 \n","Epoch  35/500, train_loss: 3.931325e-02, val_loss: 3.739092e-02 \n","Epoch  36/500, train_loss: 3.906094e-02, val_loss: 3.716066e-02 \n","Epoch  37/500, train_loss: 3.924908e-02, val_loss: 3.727955e-02 \n","Epoch  38/500, train_loss: 3.916589e-02, val_loss: 3.698495e-02 \n","Epoch  39/500, train_loss: 3.929880e-02, val_loss: 3.731698e-02 \n","Epoch  40/500, train_loss: 3.917244e-02, val_loss: 3.722322e-02 \n","Epoch  41/500, train_loss: 3.903172e-02, val_loss: 3.726943e-02 \n","Epoch  42/500, train_loss: 3.916045e-02, val_loss: 3.731451e-02 \n","Epoch  43/500, train_loss: 3.926558e-02, val_loss: 3.707513e-02 \n","Epoch  44/500, train_loss: 3.907983e-02, val_loss: 3.727850e-02 \n","Epoch  45/500, train_loss: 3.914473e-02, val_loss: 3.741537e-02 \n","Epoch  46/500, train_loss: 3.918384e-02, val_loss: 3.701940e-02 \n","Epoch  47/500, train_loss: 3.905490e-02, val_loss: 3.706548e-02 \n","Epoch  48/500, train_loss: 3.911762e-02, val_loss: 3.727261e-02 \n","Epoch  49/500, train_loss: 3.933408e-02, val_loss: 3.720713e-02 \n","Epoch  50/500, train_loss: 3.909344e-02, val_loss: 3.729422e-02 \n","Epoch  51/500, train_loss: 3.912893e-02, val_loss: 3.730277e-02 \n","Epoch  52/500, train_loss: 3.907645e-02, val_loss: 3.729197e-02 \n","Epoch  53/500, train_loss: 3.904859e-02, val_loss: 3.720517e-02 \n","Epoch  54/500, train_loss: 3.906493e-02, val_loss: 3.734627e-02 \n","Epoch  55/500, train_loss: 3.906628e-02, val_loss: 3.745854e-02 \n","Epoch  56/500, train_loss: 3.916303e-02, val_loss: 3.725780e-02 \n","Epoch  57/500, train_loss: 3.923450e-02, val_loss: 3.726857e-02 \n","Epoch  58/500, train_loss: 3.927084e-02, val_loss: 3.699467e-02 \n","Epoch  59/500, train_loss: 3.909022e-02, val_loss: 3.708956e-02 \n","Epoch  60/500, train_loss: 3.911754e-02, val_loss: 3.719538e-02 \n","Epoch  61/500, train_loss: 3.909325e-02, val_loss: 3.741662e-02 \n","Epoch  62/500, train_loss: 3.910535e-02, val_loss: 3.746775e-02 \n","Epoch  63/500, train_loss: 3.913228e-02, val_loss: 3.726643e-02 \n","Epoch  64/500, train_loss: 3.908171e-02, val_loss: 3.726173e-02 \n","Epoch  65/500, train_loss: 3.910454e-02, val_loss: 3.730791e-02 \n","Epoch  66/500, train_loss: 3.913804e-02, val_loss: 3.729717e-02 \n","Epoch  67/500, train_loss: 3.911805e-02, val_loss: 3.755878e-02 \n","Epoch  68/500, train_loss: 3.934646e-02, val_loss: 3.711526e-02 \n","Epoch  69/500, train_loss: 3.924768e-02, val_loss: 3.717348e-02 \n","Epoch  70/500, train_loss: 3.908678e-02, val_loss: 3.740647e-02 \n","Epoch  71/500, train_loss: 3.920500e-02, val_loss: 3.706363e-02 \n","Epoch  72/500, train_loss: 3.919204e-02, val_loss: 3.709326e-02 \n","Epoch  73/500, train_loss: 3.914556e-02, val_loss: 3.733690e-02 \n","Epoch  74/500, train_loss: 3.921376e-02, val_loss: 3.709854e-02 \n","Epoch  75/500, train_loss: 3.923691e-02, val_loss: 3.718938e-02 \n","Epoch  76/500, train_loss: 3.959518e-02, val_loss: 3.755596e-02 \n","Epoch  77/500, train_loss: 3.917832e-02, val_loss: 3.718528e-02 \n","Epoch  78/500, train_loss: 3.941240e-02, val_loss: 3.727277e-02 \n","Epoch  79/500, train_loss: 3.909608e-02, val_loss: 3.724995e-02 \n","Epoch  80/500, train_loss: 3.906080e-02, val_loss: 3.735808e-02 \n","Epoch  81/500, train_loss: 3.915681e-02, val_loss: 3.724902e-02 \n","Epoch  82/500, train_loss: 3.917235e-02, val_loss: 3.708111e-02 \n","Epoch  83/500, train_loss: 3.911099e-02, val_loss: 3.716286e-02 \n","Epoch  84/500, train_loss: 3.910472e-02, val_loss: 3.740664e-02 \n","Epoch  85/500, train_loss: 3.910312e-02, val_loss: 3.744890e-02 \n","Epoch  86/500, train_loss: 3.907221e-02, val_loss: 3.753766e-02 \n","Epoch  87/500, train_loss: 3.902422e-02, val_loss: 3.705601e-02 \n","Epoch  88/500, train_loss: 3.903091e-02, val_loss: 3.730882e-02 \n","Epoch  89/500, train_loss: 3.912069e-02, val_loss: 3.729842e-02 \n","Epoch  90/500, train_loss: 3.913101e-02, val_loss: 3.734983e-02 \n","Epoch  91/500, train_loss: 3.928272e-02, val_loss: 3.718705e-02 \n","Epoch  92/500, train_loss: 3.907571e-02, val_loss: 3.704649e-02 \n","Epoch  93/500, train_loss: 3.930926e-02, val_loss: 3.739499e-02 \n","Epoch  94/500, train_loss: 3.907959e-02, val_loss: 3.729884e-02 \n","Epoch  95/500, train_loss: 3.913895e-02, val_loss: 3.720518e-02 \n","Epoch  96/500, train_loss: 3.903678e-02, val_loss: 3.713121e-02 \n","Epoch  97/500, train_loss: 3.916644e-02, val_loss: 3.735407e-02 \n","Epoch  98/500, train_loss: 3.921264e-02, val_loss: 3.742580e-02 \n","Epoch  99/500, train_loss: 3.908428e-02, val_loss: 3.709058e-02 \n","Epoch 100/500, train_loss: 3.913702e-02, val_loss: 3.735414e-02 \n","Epoch 101/500, train_loss: 3.936235e-02, val_loss: 3.724857e-02 \n","Epoch 102/500, train_loss: 3.905161e-02, val_loss: 3.744654e-02 \n","Epoch 103/500, train_loss: 3.911888e-02, val_loss: 3.714856e-02 \n","Epoch 104/500, train_loss: 3.911824e-02, val_loss: 3.716256e-02 \n","Epoch 105/500, train_loss: 3.908516e-02, val_loss: 3.724698e-02 \n","Epoch 106/500, train_loss: 3.919922e-02, val_loss: 3.707608e-02 \n","Epoch 107/500, train_loss: 3.924016e-02, val_loss: 3.696092e-02 \n","Epoch 108/500, train_loss: 3.921984e-02, val_loss: 3.738746e-02 \n","Epoch 109/500, train_loss: 3.905347e-02, val_loss: 3.742360e-02 \n","Epoch 110/500, train_loss: 3.918349e-02, val_loss: 3.714076e-02 \n","Epoch 111/500, train_loss: 3.915031e-02, val_loss: 3.726059e-02 \n","Epoch 112/500, train_loss: 3.907362e-02, val_loss: 3.753526e-02 \n","Epoch 113/500, train_loss: 3.926518e-02, val_loss: 3.719728e-02 \n","Epoch 114/500, train_loss: 3.907619e-02, val_loss: 3.715048e-02 \n","Epoch 115/500, train_loss: 3.924144e-02, val_loss: 3.735225e-02 \n","Epoch 116/500, train_loss: 3.903590e-02, val_loss: 3.717074e-02 \n","Epoch 117/500, train_loss: 3.924556e-02, val_loss: 3.725844e-02 \n","Epoch 118/500, train_loss: 3.907177e-02, val_loss: 3.722665e-02 \n","Epoch 119/500, train_loss: 3.924138e-02, val_loss: 3.713633e-02 \n","Epoch 120/500, train_loss: 3.905930e-02, val_loss: 3.732782e-02 \n","Epoch 121/500, train_loss: 3.907734e-02, val_loss: 3.727490e-02 \n","Epoch 122/500, train_loss: 3.909273e-02, val_loss: 3.721737e-02 \n","Epoch 123/500, train_loss: 3.909121e-02, val_loss: 3.733461e-02 \n","Epoch 124/500, train_loss: 3.918105e-02, val_loss: 3.709516e-02 \n","Epoch 125/500, train_loss: 3.908795e-02, val_loss: 3.752413e-02 \n","Epoch 126/500, train_loss: 3.920948e-02, val_loss: 3.732805e-02 \n","Epoch 127/500, train_loss: 3.917951e-02, val_loss: 3.698401e-02 \n","Epoch 128/500, train_loss: 3.919286e-02, val_loss: 3.725278e-02 \n","Epoch 129/500, train_loss: 3.918123e-02, val_loss: 3.716957e-02 \n","Epoch 130/500, train_loss: 3.922213e-02, val_loss: 3.731597e-02 \n","Epoch 131/500, train_loss: 3.911297e-02, val_loss: 3.714545e-02 \n","Epoch 132/500, train_loss: 3.907632e-02, val_loss: 3.746054e-02 \n","Epoch 133/500, train_loss: 3.915766e-02, val_loss: 3.729029e-02 \n","Epoch 134/500, train_loss: 3.907842e-02, val_loss: 3.720277e-02 \n","Epoch 135/500, train_loss: 3.912896e-02, val_loss: 3.732016e-02 \n","Epoch 136/500, train_loss: 3.914001e-02, val_loss: 3.713452e-02 \n","Epoch 137/500, train_loss: 3.906429e-02, val_loss: 3.718091e-02 \n","Epoch 138/500, train_loss: 3.922262e-02, val_loss: 3.718412e-02 \n","Epoch 139/500, train_loss: 3.907648e-02, val_loss: 3.727457e-02 \n","Epoch 140/500, train_loss: 3.929855e-02, val_loss: 3.709385e-02 \n","Epoch 141/500, train_loss: 3.930225e-02, val_loss: 3.736370e-02 \n","Epoch 142/500, train_loss: 3.934125e-02, val_loss: 3.725233e-02 \n","Epoch 143/500, train_loss: 3.904548e-02, val_loss: 3.739450e-02 \n","Epoch 144/500, train_loss: 3.910396e-02, val_loss: 3.726028e-02 \n","Epoch 145/500, train_loss: 3.911742e-02, val_loss: 3.721271e-02 \n","Epoch 146/500, train_loss: 3.921547e-02, val_loss: 3.712426e-02 \n","Epoch 147/500, train_loss: 3.921139e-02, val_loss: 3.724334e-02 \n","Epoch 148/500, train_loss: 3.915090e-02, val_loss: 3.732952e-02 \n","Epoch 149/500, train_loss: 3.924956e-02, val_loss: 3.717559e-02 \n","Epoch 150/500, train_loss: 3.907644e-02, val_loss: 3.729976e-02 \n","Epoch 151/500, train_loss: 3.920823e-02, val_loss: 3.724764e-02 \n","Epoch 152/500, train_loss: 3.970422e-02, val_loss: 3.720216e-02 \n","Epoch 153/500, train_loss: 3.908778e-02, val_loss: 3.728278e-02 \n","Epoch 154/500, train_loss: 3.919812e-02, val_loss: 3.726362e-02 \n","Epoch 155/500, train_loss: 3.913078e-02, val_loss: 3.723850e-02 \n","Epoch 156/500, train_loss: 3.910460e-02, val_loss: 3.709183e-02 \n","Epoch 157/500, train_loss: 3.909320e-02, val_loss: 3.740802e-02 \n","Epoch 158/500, train_loss: 3.908108e-02, val_loss: 3.721151e-02 \n","Epoch 159/500, train_loss: 3.904489e-02, val_loss: 3.738959e-02 \n","Epoch 160/500, train_loss: 3.960360e-02, val_loss: 3.742621e-02 \n","Epoch 161/500, train_loss: 3.908470e-02, val_loss: 3.711649e-02 \n","Epoch 162/500, train_loss: 3.916756e-02, val_loss: 3.755389e-02 \n","Epoch 163/500, train_loss: 3.916793e-02, val_loss: 3.744490e-02 \n","Epoch 164/500, train_loss: 3.902608e-02, val_loss: 3.726211e-02 \n","Epoch 165/500, train_loss: 3.916722e-02, val_loss: 3.721813e-02 \n","Epoch 166/500, train_loss: 3.920959e-02, val_loss: 3.717226e-02 \n","Epoch 167/500, train_loss: 3.933408e-02, val_loss: 3.708377e-02 \n","Epoch 168/500, train_loss: 3.911922e-02, val_loss: 3.720429e-02 \n","Epoch 169/500, train_loss: 3.919353e-02, val_loss: 3.741390e-02 \n","Epoch 170/500, train_loss: 3.918289e-02, val_loss: 3.748915e-02 \n","Epoch 171/500, train_loss: 3.917313e-02, val_loss: 3.713952e-02 \n","Epoch 172/500, train_loss: 3.924533e-02, val_loss: 3.742966e-02 \n","Epoch 173/500, train_loss: 3.923062e-02, val_loss: 3.699592e-02 \n","Epoch 174/500, train_loss: 3.905709e-02, val_loss: 3.736639e-02 \n","Epoch 175/500, train_loss: 3.909907e-02, val_loss: 3.731691e-02 \n","Epoch 176/500, train_loss: 3.913510e-02, val_loss: 3.740619e-02 \n","Epoch 177/500, train_loss: 3.920190e-02, val_loss: 3.712899e-02 \n","Epoch 178/500, train_loss: 3.909284e-02, val_loss: 3.729627e-02 \n","Epoch 179/500, train_loss: 3.917593e-02, val_loss: 3.703026e-02 \n","Epoch 180/500, train_loss: 3.910645e-02, val_loss: 3.717774e-02 \n","Epoch 181/500, train_loss: 3.922400e-02, val_loss: 3.734707e-02 \n","Epoch 182/500, train_loss: 3.904582e-02, val_loss: 3.725706e-02 \n","Epoch 183/500, train_loss: 3.906854e-02, val_loss: 3.720557e-02 \n","Epoch 184/500, train_loss: 3.916198e-02, val_loss: 3.736870e-02 \n","Epoch 185/500, train_loss: 3.917137e-02, val_loss: 3.732036e-02 \n","Epoch 186/500, train_loss: 3.909177e-02, val_loss: 3.703487e-02 \n","Epoch 187/500, train_loss: 3.918854e-02, val_loss: 3.716916e-02 \n","Epoch 188/500, train_loss: 3.914864e-02, val_loss: 3.724614e-02 \n","Epoch 189/500, train_loss: 3.940174e-02, val_loss: 3.709275e-02 \n","Epoch 190/500, train_loss: 3.922932e-02, val_loss: 3.744064e-02 \n","Epoch 191/500, train_loss: 3.906411e-02, val_loss: 3.719294e-02 \n","Epoch 192/500, train_loss: 3.908699e-02, val_loss: 3.737471e-02 \n","Epoch 193/500, train_loss: 3.914893e-02, val_loss: 3.719285e-02 \n","Epoch 194/500, train_loss: 3.919573e-02, val_loss: 3.704064e-02 \n","Epoch 195/500, train_loss: 3.929903e-02, val_loss: 3.741766e-02 \n","Epoch 196/500, train_loss: 3.911059e-02, val_loss: 3.707489e-02 \n","Epoch 197/500, train_loss: 3.902049e-02, val_loss: 3.707465e-02 \n","Epoch 198/500, train_loss: 3.925532e-02, val_loss: 3.746644e-02 \n","Epoch 199/500, train_loss: 3.913324e-02, val_loss: 3.759263e-02 \n","Epoch 200/500, train_loss: 3.916540e-02, val_loss: 3.722103e-02 \n","Epoch 201/500, train_loss: 3.917775e-02, val_loss: 3.724431e-02 \n","Epoch 202/500, train_loss: 3.906659e-02, val_loss: 3.726947e-02 \n","Epoch 203/500, train_loss: 3.931827e-02, val_loss: 3.730273e-02 \n","Epoch 204/500, train_loss: 3.911930e-02, val_loss: 3.719664e-02 \n","Epoch 205/500, train_loss: 3.922935e-02, val_loss: 3.718539e-02 \n","Epoch 206/500, train_loss: 3.910943e-02, val_loss: 3.720391e-02 \n","Epoch 207/500, train_loss: 3.908301e-02, val_loss: 3.714781e-02 \n","Epoch 208/500, train_loss: 3.903228e-02, val_loss: 3.710248e-02 \n","Epoch 209/500, train_loss: 3.903591e-02, val_loss: 3.729014e-02 \n","Epoch 210/500, train_loss: 3.907753e-02, val_loss: 3.749024e-02 \n","Epoch 211/500, train_loss: 3.921647e-02, val_loss: 3.703151e-02 \n","Epoch 212/500, train_loss: 3.907164e-02, val_loss: 3.717546e-02 \n","Epoch 213/500, train_loss: 3.909190e-02, val_loss: 3.727139e-02 \n","Epoch 214/500, train_loss: 3.902885e-02, val_loss: 3.721946e-02 \n","Epoch 215/500, train_loss: 3.908421e-02, val_loss: 3.702371e-02 \n","Epoch 216/500, train_loss: 3.905353e-02, val_loss: 3.717232e-02 \n","Epoch 217/500, train_loss: 3.916685e-02, val_loss: 3.726042e-02 \n","Epoch 218/500, train_loss: 3.914040e-02, val_loss: 3.706408e-02 \n","Epoch 219/500, train_loss: 3.916293e-02, val_loss: 3.731450e-02 \n","Epoch 220/500, train_loss: 3.928756e-02, val_loss: 3.715212e-02 \n","Epoch 221/500, train_loss: 3.916012e-02, val_loss: 3.710654e-02 \n","Epoch 222/500, train_loss: 3.911754e-02, val_loss: 3.711620e-02 \n","Epoch 223/500, train_loss: 3.918377e-02, val_loss: 3.720144e-02 \n","Epoch 224/500, train_loss: 3.924309e-02, val_loss: 3.719316e-02 \n","Epoch 225/500, train_loss: 3.910088e-02, val_loss: 3.704307e-02 \n","Epoch 226/500, train_loss: 3.918947e-02, val_loss: 3.718810e-02 \n","Epoch 227/500, train_loss: 3.921452e-02, val_loss: 3.715837e-02 \n","Epoch 228/500, train_loss: 3.906011e-02, val_loss: 3.731761e-02 \n","Epoch 229/500, train_loss: 3.912857e-02, val_loss: 3.727488e-02 \n","Epoch 230/500, train_loss: 3.907005e-02, val_loss: 3.704916e-02 \n","Epoch 231/500, train_loss: 3.906166e-02, val_loss: 3.737418e-02 \n","Epoch 232/500, train_loss: 3.926330e-02, val_loss: 3.721940e-02 \n","Epoch 233/500, train_loss: 3.904309e-02, val_loss: 3.727641e-02 \n","Epoch 234/500, train_loss: 3.926650e-02, val_loss: 3.702286e-02 \n","Epoch 235/500, train_loss: 3.916702e-02, val_loss: 3.723679e-02 \n","Epoch 236/500, train_loss: 3.908854e-02, val_loss: 3.749045e-02 \n","Epoch 237/500, train_loss: 3.905081e-02, val_loss: 3.716307e-02 \n","Epoch 238/500, train_loss: 3.914095e-02, val_loss: 3.712583e-02 \n","Epoch 239/500, train_loss: 3.907087e-02, val_loss: 3.712410e-02 \n","Epoch 240/500, train_loss: 3.914118e-02, val_loss: 3.708468e-02 \n","Epoch 241/500, train_loss: 3.919220e-02, val_loss: 3.718178e-02 \n","Epoch 242/500, train_loss: 3.928298e-02, val_loss: 3.720352e-02 \n","Epoch 243/500, train_loss: 3.919751e-02, val_loss: 3.720115e-02 \n","Epoch 244/500, train_loss: 3.903726e-02, val_loss: 3.743971e-02 \n","Epoch 245/500, train_loss: 3.909204e-02, val_loss: 3.714357e-02 \n","Epoch 246/500, train_loss: 3.910694e-02, val_loss: 3.726745e-02 \n","Epoch 247/500, train_loss: 3.909255e-02, val_loss: 3.731706e-02 \n","Epoch 248/500, train_loss: 3.908063e-02, val_loss: 3.719218e-02 \n","Epoch 249/500, train_loss: 3.905967e-02, val_loss: 3.719127e-02 \n","Epoch 250/500, train_loss: 3.916090e-02, val_loss: 3.719808e-02 \n","Epoch 251/500, train_loss: 3.910492e-02, val_loss: 3.743876e-02 \n","Epoch 252/500, train_loss: 3.910429e-02, val_loss: 3.706203e-02 \n","Epoch 253/500, train_loss: 3.909998e-02, val_loss: 3.735279e-02 \n","Epoch 254/500, train_loss: 3.922808e-02, val_loss: 3.713556e-02 \n","Epoch 255/500, train_loss: 3.921201e-02, val_loss: 3.708924e-02 \n","Epoch 256/500, train_loss: 3.919301e-02, val_loss: 3.708919e-02 \n","Epoch 257/500, train_loss: 3.907736e-02, val_loss: 3.723858e-02 \n","Epoch 258/500, train_loss: 3.919265e-02, val_loss: 3.698904e-02 \n","Epoch 259/500, train_loss: 3.930765e-02, val_loss: 3.738049e-02 \n","Epoch 260/500, train_loss: 3.915273e-02, val_loss: 3.716067e-02 \n","Epoch 261/500, train_loss: 3.913100e-02, val_loss: 3.712845e-02 \n","Epoch 262/500, train_loss: 3.906698e-02, val_loss: 3.704231e-02 \n","Epoch 263/500, train_loss: 3.906651e-02, val_loss: 3.713469e-02 \n","Epoch 264/500, train_loss: 3.914945e-02, val_loss: 3.744674e-02 \n","Epoch 265/500, train_loss: 3.911670e-02, val_loss: 3.709069e-02 \n","Epoch 266/500, train_loss: 3.908700e-02, val_loss: 3.715402e-02 \n","Epoch 267/500, train_loss: 3.908404e-02, val_loss: 3.742277e-02 \n","Epoch 268/500, train_loss: 3.906077e-02, val_loss: 3.721860e-02 \n","Epoch 269/500, train_loss: 3.920764e-02, val_loss: 3.709398e-02 \n","Epoch 270/500, train_loss: 3.910408e-02, val_loss: 3.705652e-02 \n","Epoch 271/500, train_loss: 3.912696e-02, val_loss: 3.705124e-02 \n","Epoch 272/500, train_loss: 3.908654e-02, val_loss: 3.710712e-02 \n","Epoch 273/500, train_loss: 3.906451e-02, val_loss: 3.715221e-02 \n","Epoch 274/500, train_loss: 3.906408e-02, val_loss: 3.703188e-02 \n","Epoch 275/500, train_loss: 3.940888e-02, val_loss: 3.718749e-02 \n","Epoch 276/500, train_loss: 3.915653e-02, val_loss: 3.721230e-02 \n","Epoch 277/500, train_loss: 3.935952e-02, val_loss: 3.712545e-02 \n","Epoch 278/500, train_loss: 3.911052e-02, val_loss: 3.735859e-02 \n","Epoch 279/500, train_loss: 3.921924e-02, val_loss: 3.738208e-02 \n","Epoch 280/500, train_loss: 3.916269e-02, val_loss: 3.734795e-02 \n","Epoch 281/500, train_loss: 3.916250e-02, val_loss: 3.714119e-02 \n","Epoch 282/500, train_loss: 3.934190e-02, val_loss: 3.722189e-02 \n","Epoch 283/500, train_loss: 3.919641e-02, val_loss: 3.718993e-02 \n","Epoch 284/500, train_loss: 3.903882e-02, val_loss: 3.758192e-02 \n","Epoch 285/500, train_loss: 3.913363e-02, val_loss: 3.713345e-02 \n","Epoch 286/500, train_loss: 3.914040e-02, val_loss: 3.733906e-02 \n","Epoch 287/500, train_loss: 3.904799e-02, val_loss: 3.704674e-02 \n","Epoch 288/500, train_loss: 3.918543e-02, val_loss: 3.723713e-02 \n","Epoch 289/500, train_loss: 3.919454e-02, val_loss: 3.702031e-02 \n","Epoch 290/500, train_loss: 3.916867e-02, val_loss: 3.700620e-02 \n","Epoch 291/500, train_loss: 3.910707e-02, val_loss: 3.732067e-02 \n","Epoch 292/500, train_loss: 3.910014e-02, val_loss: 3.708944e-02 \n","Epoch 293/500, train_loss: 3.916197e-02, val_loss: 3.734135e-02 \n","Epoch 294/500, train_loss: 3.928049e-02, val_loss: 3.706986e-02 \n","Epoch 295/500, train_loss: 3.913457e-02, val_loss: 3.749595e-02 \n","Epoch 296/500, train_loss: 3.908970e-02, val_loss: 3.731101e-02 \n","Epoch 297/500, train_loss: 3.905413e-02, val_loss: 3.699773e-02 \n","Epoch 298/500, train_loss: 3.909256e-02, val_loss: 3.704324e-02 \n","Epoch 299/500, train_loss: 3.915622e-02, val_loss: 3.709557e-02 \n","Epoch 300/500, train_loss: 3.910630e-02, val_loss: 3.713592e-02 \n","Epoch 301/500, train_loss: 3.910481e-02, val_loss: 3.711573e-02 \n","Epoch 302/500, train_loss: 3.908923e-02, val_loss: 3.737697e-02 \n","Epoch 303/500, train_loss: 3.907899e-02, val_loss: 3.727657e-02 \n","Epoch 304/500, train_loss: 3.943268e-02, val_loss: 3.717432e-02 \n","Epoch 305/500, train_loss: 3.909219e-02, val_loss: 3.712870e-02 \n","Epoch 306/500, train_loss: 3.911291e-02, val_loss: 3.723689e-02 \n","Epoch 307/500, train_loss: 3.914483e-02, val_loss: 3.731482e-02 \n","Epoch 308/500, train_loss: 3.906165e-02, val_loss: 3.730420e-02 \n","Epoch 309/500, train_loss: 3.943141e-02, val_loss: 3.704204e-02 \n","Epoch 310/500, train_loss: 3.914502e-02, val_loss: 3.719041e-02 \n","Epoch 311/500, train_loss: 3.925071e-02, val_loss: 3.715525e-02 \n","Epoch 312/500, train_loss: 3.904829e-02, val_loss: 3.717852e-02 \n","Epoch 313/500, train_loss: 3.937220e-02, val_loss: 3.716017e-02 \n","Epoch 314/500, train_loss: 3.906886e-02, val_loss: 3.722767e-02 \n","Epoch 315/500, train_loss: 3.921252e-02, val_loss: 3.726707e-02 \n","Epoch 316/500, train_loss: 3.920813e-02, val_loss: 3.721582e-02 \n","Epoch 317/500, train_loss: 3.915410e-02, val_loss: 3.730611e-02 \n","Epoch 318/500, train_loss: 3.913692e-02, val_loss: 3.722447e-02 \n","Epoch 319/500, train_loss: 3.911288e-02, val_loss: 3.708673e-02 \n","Epoch 320/500, train_loss: 3.905060e-02, val_loss: 3.701796e-02 \n","Epoch 321/500, train_loss: 3.908394e-02, val_loss: 3.747925e-02 \n","Epoch 322/500, train_loss: 3.911457e-02, val_loss: 3.752678e-02 \n","Epoch 323/500, train_loss: 3.907665e-02, val_loss: 3.728102e-02 \n","Epoch 324/500, train_loss: 3.914559e-02, val_loss: 3.734861e-02 \n","Epoch 325/500, train_loss: 3.911852e-02, val_loss: 3.731749e-02 \n","Epoch 326/500, train_loss: 3.923026e-02, val_loss: 3.727649e-02 \n","Epoch 327/500, train_loss: 3.916954e-02, val_loss: 3.732818e-02 \n","Epoch 328/500, train_loss: 3.907274e-02, val_loss: 3.710847e-02 \n","Epoch 329/500, train_loss: 3.917602e-02, val_loss: 3.721299e-02 \n","Epoch 330/500, train_loss: 3.908194e-02, val_loss: 3.722029e-02 \n","Epoch 331/500, train_loss: 3.904972e-02, val_loss: 3.709353e-02 \n","Epoch 332/500, train_loss: 3.912445e-02, val_loss: 3.723939e-02 \n","Epoch 333/500, train_loss: 3.916102e-02, val_loss: 3.705401e-02 \n","Epoch 334/500, train_loss: 3.926816e-02, val_loss: 3.710118e-02 \n","Epoch 335/500, train_loss: 3.907641e-02, val_loss: 3.716864e-02 \n","Epoch 336/500, train_loss: 3.911444e-02, val_loss: 3.740634e-02 \n","Epoch 337/500, train_loss: 3.911106e-02, val_loss: 3.726133e-02 \n","Epoch 338/500, train_loss: 3.912834e-02, val_loss: 3.715528e-02 \n","Epoch 339/500, train_loss: 3.924040e-02, val_loss: 3.714719e-02 \n","Epoch 340/500, train_loss: 3.916767e-02, val_loss: 3.746358e-02 \n","Epoch 341/500, train_loss: 3.906805e-02, val_loss: 3.734594e-02 \n","Epoch 342/500, train_loss: 3.905206e-02, val_loss: 3.724116e-02 \n","Epoch 343/500, train_loss: 3.904213e-02, val_loss: 3.723547e-02 \n","Epoch 344/500, train_loss: 3.912009e-02, val_loss: 3.719874e-02 \n","Epoch 345/500, train_loss: 3.911035e-02, val_loss: 3.706989e-02 \n","Epoch 346/500, train_loss: 3.924617e-02, val_loss: 3.742461e-02 \n","Epoch 347/500, train_loss: 3.909193e-02, val_loss: 3.725258e-02 \n","Epoch 348/500, train_loss: 3.910993e-02, val_loss: 3.743867e-02 \n","Epoch 349/500, train_loss: 3.918392e-02, val_loss: 3.731386e-02 \n","Epoch 350/500, train_loss: 3.919043e-02, val_loss: 3.729345e-02 \n","Epoch 351/500, train_loss: 3.912797e-02, val_loss: 3.731054e-02 \n","Epoch 352/500, train_loss: 3.907150e-02, val_loss: 3.712444e-02 \n","Epoch 353/500, train_loss: 3.910431e-02, val_loss: 3.731851e-02 \n","Epoch 354/500, train_loss: 3.912682e-02, val_loss: 3.713243e-02 \n","Epoch 355/500, train_loss: 3.914383e-02, val_loss: 3.725599e-02 \n","Epoch 356/500, train_loss: 3.909744e-02, val_loss: 3.741161e-02 \n","Epoch 357/500, train_loss: 3.957655e-02, val_loss: 3.708234e-02 \n","Epoch 358/500, train_loss: 3.926586e-02, val_loss: 3.754942e-02 \n","Epoch 359/500, train_loss: 3.929720e-02, val_loss: 3.706168e-02 \n","Epoch 360/500, train_loss: 3.921402e-02, val_loss: 3.729935e-02 \n","Epoch 361/500, train_loss: 3.914379e-02, val_loss: 3.742915e-02 \n","Epoch 362/500, train_loss: 3.914332e-02, val_loss: 3.718491e-02 \n","Epoch 363/500, train_loss: 3.915510e-02, val_loss: 3.714729e-02 \n","Epoch 364/500, train_loss: 3.908893e-02, val_loss: 3.724820e-02 \n","Epoch 365/500, train_loss: 3.908178e-02, val_loss: 3.723997e-02 \n","Epoch 366/500, train_loss: 3.941329e-02, val_loss: 3.731580e-02 \n","Epoch 367/500, train_loss: 3.916933e-02, val_loss: 3.719984e-02 \n","Epoch 368/500, train_loss: 3.902305e-02, val_loss: 3.756022e-02 \n","Epoch 369/500, train_loss: 3.905343e-02, val_loss: 3.722452e-02 \n","Epoch 370/500, train_loss: 3.908411e-02, val_loss: 3.724936e-02 \n","Epoch 371/500, train_loss: 3.919181e-02, val_loss: 3.729615e-02 \n","Epoch 372/500, train_loss: 3.927953e-02, val_loss: 3.737615e-02 \n","Epoch 373/500, train_loss: 3.904999e-02, val_loss: 3.717617e-02 \n","Epoch 374/500, train_loss: 3.905341e-02, val_loss: 3.749199e-02 \n","Epoch 375/500, train_loss: 3.927229e-02, val_loss: 3.728347e-02 \n","Epoch 376/500, train_loss: 3.929256e-02, val_loss: 3.728393e-02 \n","Epoch 377/500, train_loss: 3.910561e-02, val_loss: 3.715314e-02 \n","Epoch 378/500, train_loss: 3.925735e-02, val_loss: 3.727067e-02 \n","Epoch 379/500, train_loss: 3.906000e-02, val_loss: 3.710923e-02 \n","Epoch 380/500, train_loss: 3.906367e-02, val_loss: 3.741845e-02 \n","Epoch 381/500, train_loss: 3.914777e-02, val_loss: 3.748295e-02 \n","Epoch 382/500, train_loss: 3.908650e-02, val_loss: 3.711608e-02 \n","Epoch 383/500, train_loss: 3.909926e-02, val_loss: 3.712609e-02 \n","Epoch 384/500, train_loss: 3.914675e-02, val_loss: 3.714984e-02 \n","Epoch 385/500, train_loss: 3.913031e-02, val_loss: 3.740113e-02 \n","Epoch 386/500, train_loss: 3.922574e-02, val_loss: 3.745536e-02 \n","Epoch 387/500, train_loss: 3.904048e-02, val_loss: 3.703294e-02 \n","Epoch 388/500, train_loss: 3.904895e-02, val_loss: 3.715425e-02 \n","Epoch 389/500, train_loss: 3.920395e-02, val_loss: 3.743347e-02 \n","Epoch 390/500, train_loss: 3.918756e-02, val_loss: 3.752857e-02 \n","Epoch 391/500, train_loss: 3.921324e-02, val_loss: 3.731006e-02 \n","Epoch 392/500, train_loss: 3.906421e-02, val_loss: 3.723853e-02 \n","Epoch 393/500, train_loss: 3.914203e-02, val_loss: 3.719389e-02 \n","Epoch 394/500, train_loss: 3.910587e-02, val_loss: 3.708577e-02 \n","Epoch 395/500, train_loss: 3.905964e-02, val_loss: 3.715505e-02 \n","Epoch 396/500, train_loss: 3.906369e-02, val_loss: 3.730056e-02 \n","Epoch 397/500, train_loss: 3.916785e-02, val_loss: 3.725388e-02 \n","Epoch 398/500, train_loss: 3.918677e-02, val_loss: 3.728086e-02 \n","Epoch 399/500, train_loss: 3.912623e-02, val_loss: 3.707700e-02 \n","Epoch 400/500, train_loss: 3.916150e-02, val_loss: 3.703375e-02 \n","Epoch 401/500, train_loss: 3.917093e-02, val_loss: 3.710660e-02 \n","Epoch 402/500, train_loss: 3.905848e-02, val_loss: 3.738557e-02 \n","Epoch 403/500, train_loss: 3.904918e-02, val_loss: 3.728714e-02 \n","Epoch 404/500, train_loss: 3.957065e-02, val_loss: 3.720543e-02 \n","Epoch 405/500, train_loss: 3.914587e-02, val_loss: 3.717282e-02 \n","Epoch 406/500, train_loss: 3.919015e-02, val_loss: 3.711135e-02 \n","Epoch 407/500, train_loss: 3.907591e-02, val_loss: 3.707390e-02 \n","Epoch 408/500, train_loss: 3.932289e-02, val_loss: 3.734373e-02 \n","Epoch 409/500, train_loss: 3.918166e-02, val_loss: 3.738831e-02 \n","Epoch 410/500, train_loss: 3.916083e-02, val_loss: 3.739231e-02 \n","Epoch 411/500, train_loss: 3.921182e-02, val_loss: 3.711934e-02 \n","Epoch 412/500, train_loss: 3.908993e-02, val_loss: 3.733936e-02 \n","Epoch 413/500, train_loss: 3.911687e-02, val_loss: 3.723435e-02 \n","Epoch 414/500, train_loss: 3.913079e-02, val_loss: 3.713716e-02 \n","Epoch 415/500, train_loss: 3.908506e-02, val_loss: 3.707588e-02 \n","Epoch 416/500, train_loss: 3.904701e-02, val_loss: 3.700893e-02 \n","Epoch 417/500, train_loss: 3.912719e-02, val_loss: 3.752616e-02 \n","Epoch 418/500, train_loss: 3.918106e-02, val_loss: 3.696572e-02 \n","Epoch 419/500, train_loss: 3.902661e-02, val_loss: 3.709528e-02 \n","Epoch 420/500, train_loss: 3.909845e-02, val_loss: 3.724923e-02 \n","Epoch 421/500, train_loss: 3.913115e-02, val_loss: 3.717815e-02 \n","Epoch 422/500, train_loss: 3.906479e-02, val_loss: 3.739828e-02 \n","Epoch 423/500, train_loss: 3.905877e-02, val_loss: 3.713686e-02 \n","Epoch 424/500, train_loss: 3.907940e-02, val_loss: 3.738068e-02 \n","Epoch 425/500, train_loss: 3.914741e-02, val_loss: 3.718185e-02 \n","Epoch 426/500, train_loss: 3.913279e-02, val_loss: 3.746991e-02 \n","Epoch 427/500, train_loss: 3.906462e-02, val_loss: 3.709469e-02 \n","Epoch 428/500, train_loss: 3.917626e-02, val_loss: 3.733602e-02 \n","Epoch 429/500, train_loss: 3.908328e-02, val_loss: 3.705119e-02 \n","Epoch 430/500, train_loss: 3.911546e-02, val_loss: 3.725687e-02 \n","Epoch 431/500, train_loss: 3.917424e-02, val_loss: 3.730202e-02 \n","Epoch 432/500, train_loss: 3.906931e-02, val_loss: 3.717806e-02 \n","Epoch 433/500, train_loss: 3.906756e-02, val_loss: 3.722240e-02 \n","Epoch 434/500, train_loss: 3.912108e-02, val_loss: 3.723106e-02 \n","Epoch 435/500, train_loss: 3.916278e-02, val_loss: 3.728445e-02 \n","Epoch 436/500, train_loss: 3.911891e-02, val_loss: 3.703940e-02 \n","Epoch 437/500, train_loss: 3.908961e-02, val_loss: 3.722846e-02 \n","Epoch 438/500, train_loss: 3.915229e-02, val_loss: 3.712528e-02 \n","Epoch 439/500, train_loss: 3.914345e-02, val_loss: 3.715930e-02 \n","Epoch 440/500, train_loss: 3.914619e-02, val_loss: 3.708489e-02 \n","Epoch 441/500, train_loss: 3.917070e-02, val_loss: 3.710613e-02 \n","Epoch 442/500, train_loss: 3.950071e-02, val_loss: 3.710866e-02 \n","Epoch 443/500, train_loss: 3.925141e-02, val_loss: 3.701367e-02 \n","Epoch 444/500, train_loss: 3.932650e-02, val_loss: 3.728414e-02 \n","Epoch 445/500, train_loss: 3.921422e-02, val_loss: 3.736641e-02 \n","Epoch 446/500, train_loss: 3.915937e-02, val_loss: 3.701790e-02 \n","Epoch 447/500, train_loss: 3.933063e-02, val_loss: 3.722452e-02 \n","Epoch 448/500, train_loss: 3.923016e-02, val_loss: 3.724826e-02 \n","Epoch 449/500, train_loss: 3.918305e-02, val_loss: 3.760050e-02 \n","Epoch 450/500, train_loss: 3.908490e-02, val_loss: 3.721453e-02 \n","Epoch 451/500, train_loss: 3.919256e-02, val_loss: 3.721440e-02 \n","Epoch 452/500, train_loss: 3.916310e-02, val_loss: 3.725245e-02 \n","Epoch 453/500, train_loss: 3.908530e-02, val_loss: 3.693101e-02 \n","Epoch 454/500, train_loss: 3.942280e-02, val_loss: 3.757585e-02 \n","Epoch 455/500, train_loss: 3.904840e-02, val_loss: 3.730794e-02 \n","Epoch 456/500, train_loss: 3.903186e-02, val_loss: 3.739531e-02 \n","Epoch 457/500, train_loss: 3.908426e-02, val_loss: 3.723109e-02 \n","Epoch 458/500, train_loss: 3.913752e-02, val_loss: 3.714946e-02 \n","Epoch 459/500, train_loss: 3.906288e-02, val_loss: 3.742622e-02 \n","Epoch 460/500, train_loss: 3.917994e-02, val_loss: 3.748016e-02 \n","Epoch 461/500, train_loss: 3.906847e-02, val_loss: 3.735152e-02 \n","Epoch 462/500, train_loss: 3.908306e-02, val_loss: 3.734968e-02 \n","Epoch 463/500, train_loss: 3.908486e-02, val_loss: 3.705689e-02 \n","Epoch 464/500, train_loss: 3.908087e-02, val_loss: 3.739570e-02 \n","Epoch 465/500, train_loss: 3.917172e-02, val_loss: 3.724714e-02 \n","Epoch 466/500, train_loss: 3.907672e-02, val_loss: 3.724673e-02 \n","Epoch 467/500, train_loss: 3.913277e-02, val_loss: 3.759635e-02 \n","Epoch 468/500, train_loss: 3.911569e-02, val_loss: 3.712630e-02 \n","Epoch 469/500, train_loss: 3.908470e-02, val_loss: 3.714469e-02 \n","Epoch 470/500, train_loss: 3.925964e-02, val_loss: 3.707081e-02 \n","Epoch 471/500, train_loss: 3.905275e-02, val_loss: 3.719155e-02 \n","Epoch 472/500, train_loss: 3.905509e-02, val_loss: 3.714703e-02 \n","Epoch 473/500, train_loss: 3.931240e-02, val_loss: 3.731593e-02 \n","Epoch 474/500, train_loss: 3.907672e-02, val_loss: 3.707927e-02 \n","Epoch 475/500, train_loss: 3.913923e-02, val_loss: 3.704552e-02 \n","Epoch 476/500, train_loss: 3.911725e-02, val_loss: 3.717411e-02 \n","Epoch 477/500, train_loss: 3.907131e-02, val_loss: 3.728907e-02 \n","Epoch 478/500, train_loss: 3.903334e-02, val_loss: 3.751388e-02 \n","Epoch 479/500, train_loss: 3.909544e-02, val_loss: 3.736890e-02 \n","Epoch 480/500, train_loss: 3.903919e-02, val_loss: 3.720852e-02 \n","Epoch 481/500, train_loss: 3.926523e-02, val_loss: 3.697036e-02 \n","Epoch 482/500, train_loss: 3.928475e-02, val_loss: 3.722394e-02 \n","Epoch 483/500, train_loss: 3.928744e-02, val_loss: 3.724435e-02 \n","Epoch 484/500, train_loss: 3.912699e-02, val_loss: 3.731081e-02 \n","Epoch 485/500, train_loss: 3.903057e-02, val_loss: 3.709485e-02 \n","Epoch 486/500, train_loss: 3.921369e-02, val_loss: 3.717967e-02 \n","Epoch 487/500, train_loss: 3.914312e-02, val_loss: 3.716518e-02 \n","Epoch 488/500, train_loss: 3.913618e-02, val_loss: 3.725950e-02 \n","Epoch 489/500, train_loss: 3.915094e-02, val_loss: 3.705731e-02 \n","Epoch 490/500, train_loss: 3.911227e-02, val_loss: 3.711288e-02 \n","Epoch 491/500, train_loss: 3.904648e-02, val_loss: 3.724762e-02 \n","Epoch 492/500, train_loss: 3.921145e-02, val_loss: 3.712794e-02 \n","Epoch 493/500, train_loss: 3.902795e-02, val_loss: 3.719836e-02 \n","Epoch 494/500, train_loss: 3.910813e-02, val_loss: 3.711806e-02 \n","Epoch 495/500, train_loss: 3.923622e-02, val_loss: 3.720310e-02 \n","Epoch 496/500, train_loss: 3.906382e-02, val_loss: 3.736644e-02 \n","Epoch 497/500, train_loss: 3.912815e-02, val_loss: 3.762888e-02 \n","Epoch 498/500, train_loss: 3.911384e-02, val_loss: 3.698432e-02 \n","Epoch 499/500, train_loss: 3.907701e-02, val_loss: 3.750209e-02 \n","Epoch 500/500, train_loss: 3.910802e-02, val_loss: 3.745132e-02 \n","FINISH.\n"]}],"source":["# start the main training process\n","max_epochs = 500\n","print('train_data',len(train_data))\n","num_trainbatch = np.ceil(len(train_data)/256) \n","num_valbatch = np.ceil(len(val_data)/256) \n","train_history = []\n","val_history = []\n","\n","min_loss = 100000\n","current_patience = 0\n","patience = 10\n","best_model = MyModel(neurons = [128, 256, 512, 256, 128])\n","\n","print('Start training!')\n","\n","for epoch in range(max_epochs): \n","    train_loss = run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=train_loader,\n","                           iftrain=True)\n","    train_history.append(train_loss/num_trainbatch)\n","    val_loss =  run_epoch(model=mynet,criterion=mycriterion,\n","                           optimizer=myoptimizer,dataloader=val_loader,\n","                           iftrain=False)\n","    val_history.append(val_loss/num_valbatch)\n","    #if epoch % 10 == 9:\n","    print(f\"Epoch {epoch + 1: >3}/{max_epochs}, train_loss: %e, val_loss: %e \"% \n","          (train_loss/num_trainbatch, val_loss/num_valbatch))\n","'''\n","    # early stopping\n","    if min_loss == 100000 or val_loss < min_loss :\n","        min_loss = val_loss\n","        current_patience = 0\n","        best_model = mynet\n","        #torch.save(mynet.state_dict(),'mynet.pth')\n","      \n","    else :\n","        current_patience += 1 \n","        if current_patience >= patience :\n","            print(\"Stopping early at epoch {}! min_loss: {} \".format(epoch+1, min_loss/num_valbatch)) \n","            break  ''' \n","\n","print('FINISH.')"],"id":"b784ca9a"},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1643756168021,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"e880c2ea","outputId":"a36ce920-d8f6-430f-ca22-8b6f825aaa1d"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# plot the train&validation loss curve \n","epochs = range(len(train_history))\n","plt.figure()\n","plt.plot(epochs, train_history, 'bo', label='Training loss')\n","plt.plot(epochs, val_history, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","\n","plt.legend()\n","plt.show()\n"],"id":"e880c2ea"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e02af27"},"outputs":[],"source":["# save trained model\n","torch.save(best_model.state_dict(),'/content/drive/My Drive/Project/model1and2/mynet2_8.pth')"],"id":"0e02af27"},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1643755624064,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"3062832d","outputId":"451ced2c-5ce5-458c-f032-8b15b2d0974b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":20}],"source":["mynet.load_state_dict(torch.load('/content/drive/My Drive/Project/model1and2/mynet2_7.pth'))"],"id":"3062832d"},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":729,"status":"ok","timestamp":1643756172020,"user":{"displayName":"Changyao ZHOU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14722674224397078637"},"user_tz":-60},"id":"c070c8a6","outputId":"221fc7a4-48e8-4883-e986-7062c56fe87d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]},{"output_type":"stream","name":"stdout","text":["test 0\n","prediction  : tensor([[0.0203, 0.0879]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.2104, 0.0199], device='cuda:0', dtype=torch.float64)\n","test 1\n","prediction  : tensor([[0.0206, 0.1718]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.7306, 0.1291], device='cuda:0', dtype=torch.float64)\n","test 2\n","prediction  : tensor([[0.0061, 0.0853]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.5286], device='cuda:0', dtype=torch.float64)\n","test 3\n","prediction  : tensor([[0.0214, 0.0790]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1., 1.], device='cuda:0', dtype=torch.float64)\n","test 4\n","prediction  : tensor([[-0.0159,  0.0743]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.1405], device='cuda:0', dtype=torch.float64)\n","test 5\n","prediction  : tensor([[0.0106, 0.0649]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.1810, 0.0364], device='cuda:0', dtype=torch.float64)\n","test 6\n","prediction  : tensor([[0.0122, 0.0660]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.9501, 0.2085], device='cuda:0', dtype=torch.float64)\n","test 7\n","prediction  : tensor([[0.0232, 0.1133]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.0404], device='cuda:0', dtype=torch.float64)\n","test 8\n","prediction  : tensor([[0.0163, 0.0861]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.3455], device='cuda:0', dtype=torch.float64)\n","test 9\n","prediction  : tensor([[0.0193, 0.0657]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.1515, 0.0192], device='cuda:0', dtype=torch.float64)\n","test 10\n","prediction  : tensor([[0.0117, 0.0794]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.2734], device='cuda:0', dtype=torch.float64)\n","test 11\n","prediction  : tensor([[0.0140, 0.0607]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.5581], device='cuda:0', dtype=torch.float64)\n","test 12\n","prediction  : tensor([[-0.0012,  0.0692]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.3595, 0.0178], device='cuda:0', dtype=torch.float64)\n","test 13\n","prediction  : tensor([[0.0180, 0.0761]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.6487e-15, 1.0000e+00], device='cuda:0', dtype=torch.float64)\n","test 14\n","prediction  : tensor([[-0.0041,  0.0897]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.3420, 0.0012], device='cuda:0', dtype=torch.float64)\n","test 15\n","prediction  : tensor([[0.0308, 0.0778]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.1550, 0.0665], device='cuda:0', dtype=torch.float64)\n","test 16\n","prediction  : tensor([[0.0109, 0.0934]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.5697, 0.0056], device='cuda:0', dtype=torch.float64)\n","test 17\n","prediction  : tensor([[0.0146, 0.0645]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.5396], device='cuda:0', dtype=torch.float64)\n","test 18\n","prediction  : tensor([[0.0219, 0.0851]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.0273], device='cuda:0', dtype=torch.float64)\n","test 19\n","prediction  : tensor([[0.0226, 0.0812]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.4282, -0.0293], device='cuda:0', dtype=torch.float64)\n","test 20\n","prediction  : tensor([[0.0209, 0.0758]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.6951e-16, 4.4244e-01], device='cuda:0', dtype=torch.float64)\n","test 21\n","prediction  : tensor([[0.0277, 0.0594]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1., 1.], device='cuda:0', dtype=torch.float64)\n","test 22\n","prediction  : tensor([[0.0234, 0.1270]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1., -1.], device='cuda:0', dtype=torch.float64)\n","test 23\n","prediction  : tensor([[-0.0079,  0.0757]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.1651], device='cuda:0', dtype=torch.float64)\n","test 24\n","prediction  : tensor([[0.0016, 0.0601]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1., -1.], device='cuda:0', dtype=torch.float64)\n","test 25\n","prediction  : tensor([[0.0275, 0.0569]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.3507, 0.0878], device='cuda:0', dtype=torch.float64)\n","test 26\n","prediction  : tensor([[0.0203, 0.0658]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 5.5419e-17, -7.9685e-02], device='cuda:0', dtype=torch.float64)\n","test 27\n","prediction  : tensor([[0.0100, 0.0632]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.0002, 0.0003], device='cuda:0', dtype=torch.float64)\n","test 28\n","prediction  : tensor([[0.0083, 0.0678]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.1270, -0.0483], device='cuda:0', dtype=torch.float64)\n","test 29\n","prediction  : tensor([[0.0183, 0.0976]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.2687, 0.0061], device='cuda:0', dtype=torch.float64)\n","test 30\n","prediction  : tensor([[-0.0094,  0.0956]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 7.3402e-14, -2.4632e-02], device='cuda:0', dtype=torch.float64)\n","test 31\n","prediction  : tensor([[0.0307, 0.0691]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000e+00, 5.4138e-04], device='cuda:0', dtype=torch.float64)\n","test 32\n","prediction  : tensor([[0.0039, 0.0866]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.6766], device='cuda:0', dtype=torch.float64)\n","test 33\n","prediction  : tensor([[0.0214, 0.0953]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([3.8602e-14, 6.2148e-04], device='cuda:0', dtype=torch.float64)\n","test 34\n","prediction  : tensor([[-0.0078,  0.0905]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 4.7389e-16, -2.8601e-02], device='cuda:0', dtype=torch.float64)\n","test 35\n","prediction  : tensor([[0.0320, 0.1509]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.0024], device='cuda:0', dtype=torch.float64)\n","test 36\n","prediction  : tensor([[0.0134, 0.0710]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.2605], device='cuda:0', dtype=torch.float64)\n","test 37\n","prediction  : tensor([[0.0073, 0.0622]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.0820], device='cuda:0', dtype=torch.float64)\n","test 38\n","prediction  : tensor([[0.0301, 0.0747]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.1123, 0.0148], device='cuda:0', dtype=torch.float64)\n","test 39\n","prediction  : tensor([[-0.0037,  0.0725]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 5.9913e-14, -1.1062e-01], device='cuda:0', dtype=torch.float64)\n","test 40\n","prediction  : tensor([[0.0139, 0.0873]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([9.1275e-14, 9.9241e-03], device='cuda:0', dtype=torch.float64)\n","test 41\n","prediction  : tensor([[0.0039, 0.0654]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.4988, 0.0902], device='cuda:0', dtype=torch.float64)\n","test 42\n","prediction  : tensor([[0.0126, 0.0919]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.0092], device='cuda:0', dtype=torch.float64)\n","test 43\n","prediction  : tensor([[0.0234, 0.0697]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.0663], device='cuda:0', dtype=torch.float64)\n","test 44\n","prediction  : tensor([[0.0101, 0.0620]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.1468e-14, 6.4348e-02], device='cuda:0', dtype=torch.float64)\n","test 45\n","prediction  : tensor([[0.0228, 0.1418]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.8449], device='cuda:0', dtype=torch.float64)\n","test 46\n","prediction  : tensor([[0.0131, 0.0631]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.7838, 0.0197], device='cuda:0', dtype=torch.float64)\n","test 47\n","prediction  : tensor([[0.0339, 0.0908]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.6181e-17, -2.9139e-02], device='cuda:0', dtype=torch.float64)\n","test 48\n","prediction  : tensor([[0.0344, 0.0986]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.2121], device='cuda:0', dtype=torch.float64)\n","test 49\n","prediction  : tensor([[0.0060, 0.0930]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 3.7635e-11, -1.0000e+00], device='cuda:0', dtype=torch.float64)\n","test 0\n","prediction  : tensor([[-0.0021,  0.0817]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.0043], device='cuda:0', dtype=torch.float64)\n","test 1\n","prediction  : tensor([[0.0051, 0.0674]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 5.5387e-15, -1.4578e-02], device='cuda:0', dtype=torch.float64)\n","test 2\n","prediction  : tensor([[0.0242, 0.0723]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 3.1849e-14, -4.9894e-03], device='cuda:0', dtype=torch.float64)\n","test 3\n","prediction  : tensor([[0.0298, 0.0706]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1., 1.], device='cuda:0', dtype=torch.float64)\n","test 4\n","prediction  : tensor([[0.0112, 0.0810]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.2780, 0.0786], device='cuda:0', dtype=torch.float64)\n","test 5\n","prediction  : tensor([[0.0284, 0.0638]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1., -1.], device='cuda:0', dtype=torch.float64)\n","test 6\n","prediction  : tensor([[0.0253, 0.1317]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.8229, -0.1104], device='cuda:0', dtype=torch.float64)\n","test 7\n","prediction  : tensor([[0.0219, 0.1723]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.3737e-16, 5.0204e-02], device='cuda:0', dtype=torch.float64)\n","test 8\n","prediction  : tensor([[0.0297, 0.0728]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.0825, 0.0214], device='cuda:0', dtype=torch.float64)\n","test 9\n","prediction  : tensor([[0.0394, 0.0893]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.0220], device='cuda:0', dtype=torch.float64)\n","test 10\n","prediction  : tensor([[0.0180, 0.0735]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.3209, 0.3084], device='cuda:0', dtype=torch.float64)\n","test 11\n","prediction  : tensor([[0.0482, 0.0684]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1., -1.], device='cuda:0', dtype=torch.float64)\n","test 12\n","prediction  : tensor([[0.0286, 0.0746]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 2.2141e-14, -1.6343e-02], device='cuda:0', dtype=torch.float64)\n","test 13\n","prediction  : tensor([[0.0087, 0.0720]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.1345, 0.3395], device='cuda:0', dtype=torch.float64)\n","test 14\n","prediction  : tensor([[0.0080, 0.0901]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([2.6862e-14, 1.0000e+00], device='cuda:0', dtype=torch.float64)\n","test 15\n","prediction  : tensor([[0.0011, 0.0729]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([8.6479e-15, 9.7167e-03], device='cuda:0', dtype=torch.float64)\n","test 16\n","prediction  : tensor([[0.0081, 0.0679]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.7892e-06, -7.7187e-03], device='cuda:0', dtype=torch.float64)\n","test 17\n","prediction  : tensor([[0.0048, 0.0668]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.2424], device='cuda:0', dtype=torch.float64)\n","test 18\n","prediction  : tensor([[0.0312, 0.0769]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.2909, -0.0034], device='cuda:0', dtype=torch.float64)\n","test 19\n","prediction  : tensor([[0.0151, 0.0723]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.5850e-14, 7.8655e-01], device='cuda:0', dtype=torch.float64)\n","test 20\n","prediction  : tensor([[0.0110, 0.0877]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 2.5296e-17, -4.1135e-02], device='cuda:0', dtype=torch.float64)\n","test 21\n","prediction  : tensor([[0.0245, 0.0743]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 5.0768e-14, -3.7431e-02], device='cuda:0', dtype=torch.float64)\n","test 22\n","prediction  : tensor([[0.0152, 0.0730]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.2063], device='cuda:0', dtype=torch.float64)\n","test 23\n","prediction  : tensor([[0.0315, 0.0708]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.8041, 0.1301], device='cuda:0', dtype=torch.float64)\n","test 24\n","prediction  : tensor([[0.0063, 0.0765]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.4635, -0.0991], device='cuda:0', dtype=torch.float64)\n","test 25\n","prediction  : tensor([[0.0200, 0.1650]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.6258, 0.0030], device='cuda:0', dtype=torch.float64)\n","test 26\n","prediction  : tensor([[0.0226, 0.0799]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.0907, -0.7726], device='cuda:0', dtype=torch.float64)\n","test 27\n","prediction  : tensor([[0.0235, 0.0657]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.2569, -0.0010], device='cuda:0', dtype=torch.float64)\n","test 28\n","prediction  : tensor([[0.0034, 0.0659]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.1238, -0.0291], device='cuda:0', dtype=torch.float64)\n","test 29\n","prediction  : tensor([[0.0325, 0.1107]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.0541], device='cuda:0', dtype=torch.float64)\n","test 30\n","prediction  : tensor([[0.0246, 0.0566]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([7.7943e-17, 8.0369e-01], device='cuda:0', dtype=torch.float64)\n","test 31\n","prediction  : tensor([[0.0102, 0.0685]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.4859, -0.0433], device='cuda:0', dtype=torch.float64)\n","test 32\n","prediction  : tensor([[0.0271, 0.0728]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.2886e-15, 4.2691e-02], device='cuda:0', dtype=torch.float64)\n","test 33\n","prediction  : tensor([[-0.0027,  0.0689]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([6.8117e-15, 3.4875e-05], device='cuda:0', dtype=torch.float64)\n","test 34\n","prediction  : tensor([[0.0050, 0.0948]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.1760e-14, 2.9242e-01], device='cuda:0', dtype=torch.float64)\n","test 35\n","prediction  : tensor([[0.0259, 0.1189]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([1.0000, 0.0125], device='cuda:0', dtype=torch.float64)\n","test 36\n","prediction  : tensor([[0.0292, 0.0843]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([3.2048e-13, 1.2722e-02], device='cuda:0', dtype=torch.float64)\n","test 37\n","prediction  : tensor([[0.0166, 0.1133]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.3226, 0.0087], device='cuda:0', dtype=torch.float64)\n","test 38\n","prediction  : tensor([[0.0259, 0.0781]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.1900e-12, -5.0652e-03], device='cuda:0', dtype=torch.float64)\n","test 39\n","prediction  : tensor([[0.0001, 0.0683]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.4039, -0.0149], device='cuda:0', dtype=torch.float64)\n","test 40\n","prediction  : tensor([[0.0204, 0.0896]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.7442e-16, -1.8513e-01], device='cuda:0', dtype=torch.float64)\n","test 41\n","prediction  : tensor([[0.0278, 0.0668]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.7831, 0.0900], device='cuda:0', dtype=torch.float64)\n","test 42\n","prediction  : tensor([[0.0214, 0.1239]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.3368, 0.0095], device='cuda:0', dtype=torch.float64)\n","test 43\n","prediction  : tensor([[-0.0002,  0.0673]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.7383, -0.0903], device='cuda:0', dtype=torch.float64)\n","test 44\n","prediction  : tensor([[0.0315, 0.0823]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([0.8256, 0.0357], device='cuda:0', dtype=torch.float64)\n","test 45\n","prediction  : tensor([[0.0246, 0.0834]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.2951, -0.0392], device='cuda:0', dtype=torch.float64)\n","test 46\n","prediction  : tensor([[0.0188, 0.0846]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.8183, -1.0000], device='cuda:0', dtype=torch.float64)\n","test 47\n","prediction  : tensor([[0.0045, 0.0680]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.3875, -0.2081], device='cuda:0', dtype=torch.float64)\n","test 48\n","prediction  : tensor([[-0.0027,  0.0772]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 0.2588, -1.0000], device='cuda:0', dtype=torch.float64)\n","test 49\n","prediction  : tensor([[0.0017, 0.0700]], device='cuda:0', grad_fn=<AddmmBackward0>),\n","ground truth：tensor([ 1.0000, -0.3482], device='cuda:0', dtype=torch.float64)\n"]}],"source":["# test inference \n","test_loss = 0\n","for n, data in enumerate(test_loader): \n","        X = torch.tensor(data[0]).cuda() \n","        y = torch.tensor(data[1]).cuda()\n","        if n < 2:\n","          for i, x in enumerate(X): \n","            best_model.eval()\n","            x = x[None, :]\n","            y_pred = best_model(x.to(torch.float32)) \n","            if i < 50:\n","              print('test',i)\n","              print('prediction  : {},\\nground truth：{}'.format(y_pred, y[i])) \n","              "],"id":"c070c8a6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"296dfbd2"},"outputs":[],"source":[""],"id":"296dfbd2"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"train_model2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}