{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "from models.my_datasets import MyDataset2\n",
    "from models.my_models_CNN import MyModel_CNN\n",
    "#from models.my_models_alex import MyModel_CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nROOT = './output/town04_image_data/images/'\\nOUT = './output/town04_image_data/smallimages/'\\nSIZE = (400,300)\\nimage_paths = os.listdir(ROOT)\\nimage_paths.sort()\\nfor im in image_paths:\\n    #print(im)\\n    img = cv2.imread(ROOT+im)\\n    img = cv2.resize(img, SIZE,  interpolation = cv2.INTER_AREA)\\n    cv2.imwrite(OUT+im, img)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ROOT = './output/town04_image_data/images/'\n",
    "OUT = './output/town04_image_data/smallimages/'\n",
    "SIZE = (400,300)\n",
    "image_paths = os.listdir(ROOT)\n",
    "image_paths.sort()\n",
    "for im in image_paths:\n",
    "    #print(im)\n",
    "    img = cv2.imread(ROOT+im)\n",
    "    img = cv2.resize(img, SIZE,  interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(OUT+im, img)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#### delete the data for the unstored images\\nROOT = \\'./output/town04_image_data/\\'\\nout = open(ROOT+\"alldata.txt\",\\'w\\')\\nlines=[]\\nwith open(ROOT+\"offdata_image.txt\", \\'r\\') as infile:\\n    for line in infile:\\n        line = line.rstrip()\\n        words = line.split()\\n        img = cv2.imread(ROOT+words[0])\\n        if img is None:\\n            pass\\n        else:\\n            out.write(line)\\n            out.write(\\'\\r\\n\\')\\nout.close()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#### delete the data for the unstored images\n",
    "ROOT = './output/town04_image_data/'\n",
    "out = open(ROOT+\"alldata.txt\",'w')\n",
    "lines=[]\n",
    "with open(ROOT+\"offdata_image.txt\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        line = line.rstrip()\n",
    "        words = line.split()\n",
    "        img = cv2.imread(ROOT+words[0])\n",
    "        if img is None:\n",
    "            pass\n",
    "        else:\n",
    "            out.write(line)\n",
    "            out.write('\\r\\n')\n",
    "out.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#### compute the delta imformation from the original information\\nROOT = \\'./output/town04_image_data/\\'\\nout = open(ROOT+\"delta.txt\",\\'w\\')\\ndelta_data = np.empty((0,3))\\nwith open(ROOT+\"data_image_all.txt\", \\'r\\') as infile:\\n    for line in infile:\\n        line = line.rstrip()\\n        words = line.split()\\n        newline = np.array([[float(words[1])-float(words[2]), float(words[3]), float(words[4])]])\\n        delta_data = np.append(delta_data, newline, axis=0)\\n        \\nnp.set_printoptions(threshold = np.inf)\\nout.write(str(repr(np.array(delta_data))))\\nout.close()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#### compute the delta imformation from the original information\n",
    "ROOT = './output/town04_image_data/'\n",
    "out = open(ROOT+\"delta.txt\",'w')\n",
    "delta_data = np.empty((0,3))\n",
    "with open(ROOT+\"data_image_all.txt\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        line = line.rstrip()\n",
    "        words = line.split()\n",
    "        newline = np.array([[float(words[1])-float(words[2]), float(words[3]), float(words[4])]])\n",
    "        delta_data = np.append(delta_data, newline, axis=0)\n",
    "        \n",
    "np.set_printoptions(threshold = np.inf)\n",
    "out.write(str(repr(np.array(delta_data))))\n",
    "out.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_off/traj3_000130_03_05.png -15.400992393493652 -243.2406005859375 1.716253525003117 14.71961465378797 -13.507819175720215 -254.91734313964844 2.242531307499981 10.858845505013758 0.999999999998921 -0.6993662381710568\n",
      "\n",
      "images_off/traj1_000560_04_01.png -3.52687931060791 -288.6733093261719 2.0606214260810285 9.935275923985431 -0.9093541502952576 -297.00396728515625 2.176896903486651 10.424831968028455 1.9976255905848633e-14 -0.9999999999999425\n",
      "\n",
      "images_on/000122_2.png 382.0631103515625 -183.5748748779297 1.5544274734708337 4.939576285193618 382.1448669433594 -191.1739959716797 1.5923080105000116 4.986300537786222 0.2889066660118707 -0.008141696205994675\n",
      "\n",
      "images_off/pjx_3_000760_02_12.png 334.88427734375 -123.30331420898438 3.06692880190055 4.9057189185027035 342.30889892578125 -123.26493835449219 2.1904843513682355 5.1108169200676725 0.07511022391559222 0.9999999999999616\n",
      "\n",
      "images_off/pjx_1_000550_10_12.png 382.2666015625 -196.11941528320312 1.6022976609069535 4.9378006346758445 381.37652587890625 -204.42626953125 1.3745254823557462 4.148059173895941 0.9999999999999984 0.12587970683932462\n",
      "\n",
      "images_off/traj2_000310_06_08.png -154.89781188964844 -123.68549346923828 2.6195457019586836 9.828894462537967 -147.75457763671875 -129.6750030517578 2.9463304814135105 7.836009958939835 1.0 -0.9999999999999981\n",
      "\n",
      "images_off/traj1_000690_03_17.png -120.95174407958984 -141.84519958496094 2.510810166231293 11.951344070996946 -111.58804321289062 -149.02442932128906 2.440460901824087 11.955001193491983 0.6859259474903318 0.026702265788483275\n",
      "\n",
      "images_off/traj1_000670_05_10.png -96.30934143066406 -163.01467895507812 2.3527550176445073 12.165033646338651 -88.00882720947266 -172.0624237060547 2.402091941050988 9.688015799065662 1.0 -0.1568571777995687\n",
      "\n",
      "images_off/pjx_2_000740_10_07.png 325.25811767578125 -194.82786560058594 -1.8796198157518478 4.940407653523852 327.3814697265625 -188.71107482910156 -1.9230281430976486 3.3772246806674033 0.9999999999999999 0.029601212057027648\n",
      "\n",
      "images_off/traj1_000790_07_09.png -142.3097381591797 -135.86143493652344 2.588815752456368 9.830207736207141 -134.43441772460938 -142.199462890625 -2.805724097972815 6.326271651970146 0.999999999999091 -0.9999999999994394\n",
      "\n",
      "images_off/traj1_000090_06_10.png 187.25177001953125 -395.9090270996094 -3.133739257851259 4.939648719933782 194.88156127929688 -396.72283935546875 2.943931772219676 4.931794311526913 0.3618735635261773 0.08532141910286713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preprocess the txt file\n",
    "ROOT = './output/town04_data/trajectory1_pjx/'\n",
    "train_out = open(ROOT+\"traindata_shuffle.txt\",'w')\n",
    "val_out = open(ROOT+\"valdata_shuffle.txt\",'w')\n",
    "over_out = open(ROOT+\"overdata_shuffle.txt\",'w')\n",
    "lines=[]\n",
    "with open(ROOT+\"data_all.txt\", 'r') as infile:\n",
    "    for line in infile:\n",
    "        lines.append(line)\n",
    "    random.shuffle(lines)\n",
    "    num_train = np.ceil(0.85*len(lines))\n",
    "    for count, line in enumerate(lines):\n",
    "        if count <=num_train:\n",
    "            if count>=25 and count<=35:\n",
    "                print(line)\n",
    "                over_out.write(line)\n",
    "            train_out.write(line)\n",
    "        else:\n",
    "            val_out.write(line) \n",
    "train_out.close()            \n",
    "val_out.close()\n",
    "over_out.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfit size: 11\n",
      "Train size: 53626\n",
      "Validation size: 9462\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM = transforms.Compose([#transforms.Grayscale(num_output_channels=3),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5, ))])\n",
    "\n",
    "                                #transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "SIZE = (200,150)\n",
    "over_data = MyDataset2(root = ROOT, txtname = 'overdata_shuffle.txt', transform=TRANSFORM, size=SIZE)\n",
    "train_data = MyDataset2(root = ROOT, txtname = 'traindata_shuffle.txt' , transform = TRANSFORM, size= SIZE)\n",
    "val_data = MyDataset2(root = ROOT, txtname = 'valdata_shuffle.txt', transform = TRANSFORM, size= SIZE)\n",
    "over_loader = DataLoader(dataset=over_data, batch_size=32, shuffle=True)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=32, shuffle=True)\n",
    "print(\"Overfit size: %i\" % len(over_data))\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Validation size: %i\" % len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 150, 200])\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-550740790079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mover_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Window'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mover_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "print(over_data[0][0][0].shape)\n",
    "cv2.imshow('Window',over_data[0][0][0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Defining Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel_CNN(\n",
      "  (expands): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (predict): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=3870, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mynet= MyModel_CNN().to(device)\n",
    "print(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,452,704 total parameters.\n",
      "4,452,704 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in mynet.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in mynet.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} trainable parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Training Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycriterion = nn.MSELoss(reduction='mean') \n",
    "myoptimizer = optim.Adam(mynet.parameters(), lr=1e-6, eps = 1e-08) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(model,criterion,optimizer,dataloader,iftrain):    \n",
    "    running_loss1 = 0.0  \n",
    "    running_loss2 = 0.0\n",
    "    #Iterating through the minibatches of the data\n",
    "    for i, data in enumerate(dataloader, 0): \n",
    "        X, y1, y2 = data\n",
    "        X = [x.cuda() for x in X]\n",
    "        y1 = y1.to(device).float()\n",
    "        y2 = y2.to(device).float()\n",
    "        #Y = [y.cuda() for y in Y]\n",
    "        #X = torch.tensor(X)\n",
    "        #Y = torch.as_tensor(np.array(Y))\n",
    "        #print(X.shape)\n",
    "        if iftrain:  \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            y_pred1 = y_pred[:,0].float()\n",
    "            y_pred2 = y_pred[:,1].float()\n",
    "            loss1 = criterion(y_pred1, y1)\n",
    "            loss2 = criterion(y_pred2, y2) \n",
    "            loss = loss1 + loss2\n",
    "            #print(y)\n",
    "            #print(y_pred)\n",
    "            loss.backward()             \n",
    "            optimizer.step()            \n",
    "            running_loss1 += loss1.item() \n",
    "            running_loss2 += loss2.item() \n",
    "            #print('x', X[1])\n",
    "            #print('prediction', y_pred)\n",
    "            #print('gt', y)\n",
    "        else:\n",
    "            y_pred = y_pred = model(X)\n",
    "            y_pred1 = y_pred[:,0].float()\n",
    "            y_pred2 = y_pred[:,1].float()\n",
    "            loss1 = criterion(y_pred1, y1)\n",
    "            loss2 = criterion(y_pred2, y2) \n",
    "            loss = loss1 + loss2 \n",
    "            running_loss1 += loss1.item() \n",
    "            running_loss2 += loss2.item()     \n",
    "    return running_loss1, running_loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10/200 \n",
      "Throttle: train_loss: 3.551230e-02, val_loss: 2.596163e-02 \n",
      "Steering Angle: train_loss: 3.856241e-02, val_loss: 1.803605e-02 \n",
      "Epoch  20/200 \n",
      "Throttle: train_loss: 8.009193e-03, val_loss: 2.785644e-03 \n",
      "Steering Angle: train_loss: 7.589693e-03, val_loss: 4.245000e-03 \n",
      "Epoch  30/200 \n",
      "Throttle: train_loss: 4.599959e-03, val_loss: 3.907646e-03 \n",
      "Steering Angle: train_loss: 2.240815e-03, val_loss: 1.333040e-03 \n",
      "Epoch  40/200 \n",
      "Throttle: train_loss: 8.503094e-04, val_loss: 1.316443e-03 \n",
      "Steering Angle: train_loss: 5.701184e-04, val_loss: 6.492198e-04 \n",
      "Epoch  50/200 \n",
      "Throttle: train_loss: 1.680560e-04, val_loss: 1.728353e-04 \n",
      "Steering Angle: train_loss: 3.128790e-04, val_loss: 1.996357e-04 \n",
      "Epoch  60/200 \n",
      "Throttle: train_loss: 1.674888e-04, val_loss: 9.360404e-05 \n",
      "Steering Angle: train_loss: 1.032663e-04, val_loss: 6.960880e-05 \n",
      "Epoch  70/200 \n",
      "Throttle: train_loss: 6.714362e-05, val_loss: 5.142192e-05 \n",
      "Steering Angle: train_loss: 3.441020e-05, val_loss: 2.698964e-05 \n",
      "Epoch  80/200 \n",
      "Throttle: train_loss: 1.358673e-05, val_loss: 1.545806e-05 \n",
      "Steering Angle: train_loss: 1.149561e-05, val_loss: 1.421738e-05 \n",
      "Epoch  90/200 \n",
      "Throttle: train_loss: 4.661799e-06, val_loss: 8.799079e-06 \n",
      "Steering Angle: train_loss: 3.391210e-06, val_loss: 2.939187e-06 \n",
      "Epoch 100/200 \n",
      "Throttle: train_loss: 1.732654e-06, val_loss: 2.560651e-06 \n",
      "Steering Angle: train_loss: 1.067747e-06, val_loss: 1.432556e-06 \n",
      "Epoch 110/200 \n",
      "Throttle: train_loss: 3.723572e-07, val_loss: 7.736620e-07 \n",
      "Steering Angle: train_loss: 5.660973e-07, val_loss: 6.663215e-07 \n",
      "Epoch 120/200 \n",
      "Throttle: train_loss: 3.855643e-07, val_loss: 3.955166e-07 \n",
      "Steering Angle: train_loss: 1.930906e-07, val_loss: 2.221608e-07 \n",
      "Epoch 130/200 \n",
      "Throttle: train_loss: 9.940499e-08, val_loss: 8.141624e-08 \n",
      "Steering Angle: train_loss: 1.365463e-07, val_loss: 7.829101e-08 \n",
      "Epoch 140/200 \n",
      "Throttle: train_loss: 5.374540e-08, val_loss: 1.869622e-08 \n",
      "Steering Angle: train_loss: 1.862806e-08, val_loss: 1.529555e-08 \n",
      "Epoch 150/200 \n",
      "Throttle: train_loss: 7.500079e-09, val_loss: 6.171535e-09 \n",
      "Steering Angle: train_loss: 5.951547e-09, val_loss: 4.479698e-09 \n",
      "Epoch 160/200 \n",
      "Throttle: train_loss: 2.000428e-09, val_loss: 5.368738e-09 \n",
      "Steering Angle: train_loss: 3.084351e-09, val_loss: 3.938038e-09 \n",
      "Epoch 170/200 \n",
      "Throttle: train_loss: 1.737775e-09, val_loss: 1.089986e-09 \n",
      "Steering Angle: train_loss: 1.556821e-09, val_loss: 1.309123e-09 \n",
      "Epoch 180/200 \n",
      "Throttle: train_loss: 5.242605e-10, val_loss: 4.285202e-11 \n",
      "Steering Angle: train_loss: 3.519947e-10, val_loss: 4.316924e-10 \n",
      "Epoch 190/200 \n",
      "Throttle: train_loss: 7.403768e-11, val_loss: 1.530459e-10 \n",
      "Steering Angle: train_loss: 1.313192e-10, val_loss: 2.252519e-10 \n",
      "Epoch 200/200 \n",
      "Throttle: train_loss: 1.154201e-10, val_loss: 5.837738e-11 \n",
      "Steering Angle: train_loss: 3.489441e-11, val_loss: 2.545852e-11 \n"
     ]
    }
   ],
   "source": [
    "# test if the model will overfit with only one sample\n",
    "max_epochs = 200\n",
    "train_history_th = []\n",
    "train_history_st = []\n",
    "val_history_th = []\n",
    "val_history_st = []\n",
    "myoptimizer = optim.Adam(mynet.parameters(), lr=1e-4, eps = 1e-08) \n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLR(myoptimizer, max_epochs)\n",
    "for epoch in range(max_epochs): \n",
    "    '''\n",
    "    if epoch >= 1999 and epoch <= 2999:\n",
    "        myoptimizer.param_groups[0]['lr'] = 1e-5\n",
    "    elif epoch > 2999:\n",
    "        myoptimizer.param_groups[0]['lr'] = 1e-6\n",
    "    scheduler.step()\n",
    "    '''\n",
    "    train_loss1, train_loss2 = run_epoch(model=mynet,criterion=mycriterion,\n",
    "                           optimizer=myoptimizer,dataloader=over_loader,\n",
    "                           iftrain=True)\n",
    "    train_history_th.append(train_loss1)\n",
    "    train_history_st.append(train_loss2)\n",
    "    val_loss1, val_loss2 =  run_epoch(model=mynet,criterion=mycriterion,\n",
    "                           optimizer=myoptimizer,dataloader=over_loader,\n",
    "                           iftrain=False)\n",
    "    val_history_th.append(val_loss1)\n",
    "    val_history_st.append(val_loss2)\n",
    "    if epoch % 10 == 9:\n",
    "        print(f\"Epoch {epoch + 1: >3}/{max_epochs} \\nThrottle: train_loss: %2e, val_loss: %2e \\nSteering Angle: train_loss: %2e, val_loss: %2e \"% \n",
    "          (train_loss1, val_loss1, train_loss2, val_loss2))\n",
    "        #print(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the train&validation loss curve with only one sample\n",
    "epochs = range(len(train_history_th))\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_history_th, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_history_th, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_in tensor(4.9378, device='cuda:0')\n",
      "prediction:[[1.0000051  0.12588508]], ground truth:tensor([1.0000, 0.1259], device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melina/.local/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "mynet.eval()\n",
    "TEST = random.randint (0, 11)\n",
    "test_in, gt_th, gt_st = over_data[TEST]\n",
    "test_in = [torch.tensor(x).cuda() for x in test_in]\n",
    "gt_output = [gt_th, gt_st]\n",
    "gt_output = torch.tensor(gt_output).to(device)\n",
    "output_pred = mynet(test_in) \n",
    "#print('TEST', TEST)\n",
    "print('test_in',test_in[1])\n",
    "print('prediction:{}, ground truth:{}'.format(output_pred.cpu().detach().numpy(), gt_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the main training process\n",
    "\n",
    "num_trainbatch = np.ceil(len(train_data)/32) \n",
    "num_valbatch = np.ceil(len(val_data)/32) \n",
    "train_history_th = []\n",
    "train_history_st = []\n",
    "val_history_th = []\n",
    "val_history_st = []\n",
    "\n",
    "min_loss = 100000\n",
    "current_patience = 0\n",
    "patience = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n",
      "Epoch   1/50 \n",
      "Throttle: train_loss: 1.179720e-03, val_loss: 1.870404e-02 \n",
      "Steering Angle: train_loss: 9.680483e-04, val_loss: 1.899589e-02 \n",
      "Epoch   2/50 \n",
      "Throttle: train_loss: 9.606909e-04, val_loss: 1.848582e-02 \n",
      "Steering Angle: train_loss: 8.160327e-04, val_loss: 1.899466e-02 \n",
      "Epoch   3/50 \n",
      "Throttle: train_loss: 8.516125e-04, val_loss: 1.842337e-02 \n",
      "Steering Angle: train_loss: 7.380844e-04, val_loss: 1.887489e-02 \n",
      "Epoch   4/50 \n",
      "Throttle: train_loss: 7.730620e-04, val_loss: 1.834213e-02 \n",
      "Steering Angle: train_loss: 6.810806e-04, val_loss: 1.880180e-02 \n",
      "Epoch   5/50 \n",
      "Throttle: train_loss: 7.082921e-04, val_loss: 1.823465e-02 \n",
      "Steering Angle: train_loss: 6.359492e-04, val_loss: 1.905984e-02 \n",
      "Epoch   6/50 \n",
      "Throttle: train_loss: 6.564486e-04, val_loss: 1.824716e-02 \n",
      "Steering Angle: train_loss: 5.977653e-04, val_loss: 1.877883e-02 \n",
      "Epoch   7/50 \n",
      "Throttle: train_loss: 6.125620e-04, val_loss: 1.816603e-02 \n",
      "Steering Angle: train_loss: 5.650095e-04, val_loss: 1.873514e-02 \n",
      "Epoch   8/50 \n",
      "Throttle: train_loss: 5.741508e-04, val_loss: 1.817188e-02 \n",
      "Steering Angle: train_loss: 5.362897e-04, val_loss: 1.872660e-02 \n",
      "Epoch   9/50 \n",
      "Throttle: train_loss: 5.392427e-04, val_loss: 1.812803e-02 \n",
      "Steering Angle: train_loss: 5.113611e-04, val_loss: 1.871875e-02 \n",
      "Epoch  10/50 \n",
      "Throttle: train_loss: 5.083495e-04, val_loss: 1.811249e-02 \n",
      "Steering Angle: train_loss: 4.890122e-04, val_loss: 1.867754e-02 \n",
      "Epoch  11/50 \n",
      "Throttle: train_loss: 4.792790e-04, val_loss: 1.809903e-02 \n",
      "Steering Angle: train_loss: 4.681835e-04, val_loss: 1.868321e-02 \n",
      "Epoch  12/50 \n",
      "Throttle: train_loss: 4.542115e-04, val_loss: 1.804533e-02 \n",
      "Steering Angle: train_loss: 4.493439e-04, val_loss: 1.866059e-02 \n",
      "Epoch  13/50 \n",
      "Throttle: train_loss: 4.306967e-04, val_loss: 1.806022e-02 \n",
      "Steering Angle: train_loss: 4.324253e-04, val_loss: 1.866434e-02 \n",
      "Epoch  14/50 \n",
      "Throttle: train_loss: 4.087226e-04, val_loss: 1.802219e-02 \n",
      "Steering Angle: train_loss: 4.164948e-04, val_loss: 1.866452e-02 \n",
      "Epoch  15/50 \n",
      "Throttle: train_loss: 3.886295e-04, val_loss: 1.798847e-02 \n",
      "Steering Angle: train_loss: 4.016014e-04, val_loss: 1.862194e-02 \n",
      "Epoch  16/50 \n",
      "Throttle: train_loss: 3.697910e-04, val_loss: 1.798732e-02 \n",
      "Steering Angle: train_loss: 3.882279e-04, val_loss: 1.861113e-02 \n",
      "Epoch  17/50 \n",
      "Throttle: train_loss: 3.523713e-04, val_loss: 1.797821e-02 \n",
      "Steering Angle: train_loss: 3.755851e-04, val_loss: 1.862427e-02 \n",
      "Epoch  18/50 \n",
      "Throttle: train_loss: 3.359503e-04, val_loss: 1.795725e-02 \n",
      "Steering Angle: train_loss: 3.630380e-04, val_loss: 1.860624e-02 \n",
      "Epoch  19/50 \n",
      "Throttle: train_loss: 3.205323e-04, val_loss: 1.794415e-02 \n",
      "Steering Angle: train_loss: 3.524941e-04, val_loss: 1.861158e-02 \n"
     ]
    }
   ],
   "source": [
    "myoptimizer = optim.Adam(mynet.parameters(), lr=1e-6, eps = 1e-08) \n",
    "max_epochs = 50\n",
    "print('Start training!')\n",
    "for epoch in range(max_epochs): \n",
    "    '''\n",
    "    if epoch >= 29 and epoch <= 39:\n",
    "        myoptimizer.param_groups[0]['lr'] = 1e-5\n",
    "    elif epoch > 39:\n",
    "        myoptimizer.param_groups[0]['lr'] = 1e-6\n",
    "    '''\n",
    "    train_loss1, train_loss2 = run_epoch(model=mynet,criterion=mycriterion,\n",
    "                           optimizer=myoptimizer,dataloader=train_loader,\n",
    "                           iftrain=True)\n",
    "    train_history_th.append(train_loss1/num_trainbatch)\n",
    "    train_history_st.append(train_loss2/num_trainbatch)\n",
    "    val_loss1, val_loss2 =  run_epoch(model=mynet,criterion=mycriterion,\n",
    "                           optimizer=myoptimizer,dataloader=val_loader,\n",
    "                           iftrain=False)\n",
    "    val_history_th.append(val_loss1/num_valbatch)\n",
    "    val_history_st.append(val_loss2/num_valbatch)\n",
    "    #if epoch % 10 == 9:\n",
    "    print(f\"Epoch {epoch + 1: >3}/{max_epochs} \\nThrottle: train_loss: %2e, val_loss: %2e \\nSteering Angle: train_loss: %2e, val_loss: %2e \"% \n",
    "          (train_loss1/num_trainbatch, val_loss1/num_valbatch, train_loss2/num_trainbatch, val_loss2/num_valbatch))\n",
    "'''\n",
    "    # early stopping\n",
    "    if min_loss == 100000 or val_loss < min_loss :\n",
    "        min_loss = val_loss\n",
    "        current_patience = 0\n",
    "        torch.save(mynet.state_dict(),'mynet.pth')\n",
    "      \n",
    "    else :\n",
    "        current_patience += 1 \n",
    "        if current_patience >= patience :\n",
    "            print(\"Stopping early at epoch {}!\".format(epoch+1)) \n",
    "            break   '''\n",
    "\n",
    "print('FINISH.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (23,) and (22,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-392afcb78ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history_th\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intellisys/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2757\u001b[0m     return gca().plot(\n\u001b[1;32m   2758\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intellisys/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \"\"\"\n\u001b[1;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intellisys/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intellisys/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    499\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (23,) and (22,)"
     ]
    }
   ],
   "source": [
    "# plot the train&validation loss curve \n",
    "epochs = range(len(train_history_th))\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_history_th, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_history_th, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "torch.save(mynet.state_dict(),'./models/mynet_alexnet_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet.load_state_dict(torch.load('./models/mynet_alexnet_all_4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:[[ 0.37571758 -0.02146863]], ground truth:[ 0.33001755 -0.0320853 ]\n",
      "prediction:[[ 0.49417245 -0.02807501]], ground truth:[ 0.55259206 -0.04712439]\n",
      "prediction:[[-0.00096686 -0.02700344]], ground truth:[ 4.07686433e-14 -2.76466643e-02]\n",
      "prediction:[[ 0.3470227  -0.00972778]], ground truth:[ 0.35624558 -0.0006141 ]\n",
      "prediction:[[0.97774863 0.23365976]], ground truth:[1.         0.11941857]\n",
      "prediction:[[ 0.629377   -0.19288659]], ground truth:[ 0.44922987 -0.24013502]\n",
      "prediction:[[0.26414663 0.00900005]], ground truth:[0.22469821 0.04141541]\n",
      "prediction:[[1.0165029  0.98445576]], ground truth:[1.         0.99078671]\n",
      "prediction:[[1.0424839  0.10771824]], ground truth:[1.         0.09920795]\n",
      "prediction:[[0.98704827 0.00537097]], ground truth:[1.         0.00656906]\n",
      "prediction:[[ 0.89920515 -0.5916534 ]], ground truth:[ 1.         -0.48886307]\n",
      "prediction:[[0.00513009 0.00737754]], ground truth:[ 7.49754142e-16 -8.22064573e-03]\n",
      "prediction:[[ 0.2712327  -0.04734502]], ground truth:[ 0.22366045 -0.07134576]\n",
      "prediction:[[-0.00584532  0.38522857]], ground truth:[2.19761490e-14 2.43821298e-01]\n",
      "prediction:[[-0.00554774  0.0094569 ]], ground truth:[2.83013914e-14 1.47690908e-02]\n",
      "prediction:[[ 0.98858726 -0.00105133]], ground truth:[ 1.         -0.01349725]\n",
      "prediction:[[1.005966   0.54125935]], ground truth:[1.         0.56884853]\n",
      "prediction:[[ 0.9991372  -0.00692767]], ground truth:[ 0.99999904 -0.10761351]\n",
      "prediction:[[0.7832517 0.2748112]], ground truth:[0.54782999 0.24452437]\n",
      "prediction:[[ 0.3194875  -0.00467458]], ground truth:[ 0.3296098  -0.00317049]\n",
      "prediction:[[ 0.02977929 -0.04275307]], ground truth:[ 0.         -0.07584352]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melina/.local/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range (21):\n",
    "    TEST = random.randint (0, 2900)\n",
    "    test_in, gt_th, gt_st = val_data[TEST]\n",
    "    test_in = [torch.tensor(x).cuda() for x in test_in]\n",
    "    gt_output = [gt_th, gt_st]\n",
    "    gt_output = torch.tensor(gt_output).to(device)\n",
    "    output_pred = mynet(test_in) \n",
    "    #print('TEST', TEST)\n",
    "    #print('test_in',test_in)\n",
    "    print('prediction:{}, ground truth:{}'.format(output_pred.cpu().detach().numpy(), gt_output.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
